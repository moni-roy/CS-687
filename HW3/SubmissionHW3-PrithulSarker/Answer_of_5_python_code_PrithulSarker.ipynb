{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caroline-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (a) Mounting and Data Preparation\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# from google.colab import drive\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "conservative-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (b) Hyperparameter Setup and Data Preparation\n",
    "epochs = 300\n",
    "batch_size = 32\n",
    "training_samples = 4000\n",
    "validation_samples = 600\n",
    "img_width = 152\n",
    "img_height = 152\n",
    "channels = 3\n",
    "test_samples = 200\n",
    "input_shape = (img_width, img_height, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "streaming-facing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = \"Small_set_cats_vs_dogs/Small_set_cats_vs_dogs/train\"\n",
    "val_data_dir = \"Small_set_cats_vs_dogs/Small_set_cats_vs_dogs/val\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1. /255, shear_range = 0.4, zoom_range = 0.4, rotation_range = 40, width_shift_range = 0.4,\n",
    "    height_shift_range = 0.4, horizontal_flip = True, vertical_flip = True, fill_mode = 'nearest'    \n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale = 1. / 255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir, target_size = (img_width, img_height), batch_size = batch_size, class_mode = 'binary'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir, target_size = (img_width, img_height), batch_size = batch_size, class_mode ='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attended-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (c) Model Setup\n",
    "# First Approach\n",
    "vgg_lite_model = Sequential([\n",
    "    Conv2D(input_shape = input_shape, filters = 32, kernel_size = (3, 3), padding = 'same', \n",
    "           activation = 'relu', kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 32, kernel_size = (3, 3), padding = 'same', activation = 'relu', \n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Conv2D(filters = 128, kernel_size = (3, 3), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 128, kernel_size = (3, 3), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Conv2D(filters = 256, kernel_size = (3, 3), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 256, kernel_size = (3, 3), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "    \n",
    "    Conv2D(filters = 256, kernel_size = (3, 3), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 256, kernel_size = (3, 3), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(units = 1024, activation = 'relu', kernel_initializer = 'he_uniform'),\n",
    "    Dense(units = 512, activation = 'relu', kernel_initializer = 'he_uniform'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units = 1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nearby-guide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 152, 152, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 152, 152, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 152, 152, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 76, 76, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 76, 76, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 76, 76, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 76, 76, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 38, 38, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 38, 38, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 38, 38, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 19, 19, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 19, 19, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 19, 19, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 9, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 7,076,001\n",
      "Trainable params: 7,074,529\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_lite_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(vgg_lite_model, to_file='vgg_lite_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "english-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (d) Model Training\n",
    "optimizer = SGD(learning_rate = 0.001, momentum = 0.9)\n",
    "#optimizer = RMSprop(learning_rate = 0.0001)\n",
    "vgg_lite_model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 5, verbose = 0,\n",
    "                              mode = 'auto', min_delta = 0.0001, cooldown = 0, min_lr = 0)\n",
    "snapshot_name = 'vgg_lite_model'\n",
    "checkpoint = ModelCheckpoint(filepath = snapshot_name + \".{epoch:02d}-{val_accuracy:.2f}.h5\",\n",
    "                             monitor = 'val_accuracy', verbose = 0, save_best_only = True,\n",
    "                             save_weights_only = True, mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "potential-montreal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "125/125 [==============================] - 85s 636ms/step - loss: 29.6610 - accuracy: 0.5389 - val_loss: 28.6501 - val_accuracy: 0.4983\n",
      "Epoch 2/300\n",
      "125/125 [==============================] - 68s 546ms/step - loss: 28.0195 - accuracy: 0.5484 - val_loss: 27.0484 - val_accuracy: 0.4878\n",
      "Epoch 3/300\n",
      "125/125 [==============================] - 69s 547ms/step - loss: 26.6577 - accuracy: 0.5692 - val_loss: 25.6942 - val_accuracy: 0.5434\n",
      "Epoch 4/300\n",
      "125/125 [==============================] - 66s 525ms/step - loss: 25.3767 - accuracy: 0.5724 - val_loss: 24.4450 - val_accuracy: 0.6024\n",
      "Epoch 5/300\n",
      "125/125 [==============================] - 63s 505ms/step - loss: 24.1638 - accuracy: 0.5880 - val_loss: 23.3154 - val_accuracy: 0.5382\n",
      "Epoch 6/300\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 23.0115 - accuracy: 0.5991 - val_loss: 22.1853 - val_accuracy: 0.5903\n",
      "Epoch 7/300\n",
      "125/125 [==============================] - 85s 683ms/step - loss: 21.9324 - accuracy: 0.5961 - val_loss: 21.1579 - val_accuracy: 0.5903\n",
      "Epoch 8/300\n",
      "125/125 [==============================] - 75s 602ms/step - loss: 20.8855 - accuracy: 0.6065 - val_loss: 20.1323 - val_accuracy: 0.6163\n",
      "Epoch 9/300\n",
      "125/125 [==============================] - 82s 658ms/step - loss: 19.8966 - accuracy: 0.6137 - val_loss: 19.1725 - val_accuracy: 0.6302\n",
      "Epoch 10/300\n",
      "125/125 [==============================] - 86s 685ms/step - loss: 18.9629 - accuracy: 0.6198 - val_loss: 18.2980 - val_accuracy: 0.6094\n",
      "Epoch 11/300\n",
      "125/125 [==============================] - 77s 617ms/step - loss: 18.0704 - accuracy: 0.6144 - val_loss: 17.4425 - val_accuracy: 0.6163\n",
      "Epoch 12/300\n",
      "125/125 [==============================] - 81s 651ms/step - loss: 17.2027 - accuracy: 0.6505 - val_loss: 16.6112 - val_accuracy: 0.6181\n",
      "Epoch 13/300\n",
      "125/125 [==============================] - 73s 586ms/step - loss: 16.3897 - accuracy: 0.6474 - val_loss: 15.8206 - val_accuracy: 0.6510\n",
      "Epoch 14/300\n",
      "125/125 [==============================] - 72s 574ms/step - loss: 15.6379 - accuracy: 0.6283 - val_loss: 15.0627 - val_accuracy: 0.6771\n",
      "Epoch 15/300\n",
      "125/125 [==============================] - 74s 593ms/step - loss: 14.9054 - accuracy: 0.6489 - val_loss: 14.3715 - val_accuracy: 0.6562\n",
      "Epoch 16/300\n",
      "125/125 [==============================] - 72s 575ms/step - loss: 14.2153 - accuracy: 0.6392 - val_loss: 13.7773 - val_accuracy: 0.5833\n",
      "Epoch 17/300\n",
      "125/125 [==============================] - 72s 574ms/step - loss: 13.5494 - accuracy: 0.6434 - val_loss: 13.0754 - val_accuracy: 0.6389\n",
      "Epoch 18/300\n",
      "125/125 [==============================] - 72s 577ms/step - loss: 12.9224 - accuracy: 0.6508 - val_loss: 12.4856 - val_accuracy: 0.6476\n",
      "Epoch 19/300\n",
      "125/125 [==============================] - 72s 575ms/step - loss: 12.3156 - accuracy: 0.6570 - val_loss: 11.8936 - val_accuracy: 0.6354\n",
      "Epoch 20/300\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 11.7512 - accuracy: 0.6569 - val_loss: 11.3304 - val_accuracy: 0.6858\n",
      "Epoch 21/300\n",
      "125/125 [==============================] - 71s 568ms/step - loss: 11.1971 - accuracy: 0.6778 - val_loss: 10.8121 - val_accuracy: 0.6528\n",
      "Epoch 22/300\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 10.6742 - accuracy: 0.6831 - val_loss: 10.3161 - val_accuracy: 0.6823\n",
      "Epoch 23/300\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 10.1929 - accuracy: 0.6794 - val_loss: 9.8915 - val_accuracy: 0.6615\n",
      "Epoch 24/300\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 9.7281 - accuracy: 0.6787 - val_loss: 9.4410 - val_accuracy: 0.6632\n",
      "Epoch 25/300\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 9.2889 - accuracy: 0.6783 - val_loss: 8.9678 - val_accuracy: 0.6892\n",
      "Epoch 26/300\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 8.8423 - accuracy: 0.6839 - val_loss: 8.6000 - val_accuracy: 0.6441\n",
      "Epoch 27/300\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 8.4532 - accuracy: 0.6949 - val_loss: 8.2271 - val_accuracy: 0.6198\n",
      "Epoch 28/300\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 8.0720 - accuracy: 0.7054 - val_loss: 7.7965 - val_accuracy: 0.6840\n",
      "Epoch 29/300\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 7.7190 - accuracy: 0.6819 - val_loss: 7.4322 - val_accuracy: 0.7188\n",
      "Epoch 30/300\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 7.3696 - accuracy: 0.6908 - val_loss: 7.0796 - val_accuracy: 0.7378\n",
      "Epoch 31/300\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 7.0429 - accuracy: 0.7033 - val_loss: 6.7993 - val_accuracy: 0.7066\n",
      "Epoch 32/300\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 6.7320 - accuracy: 0.6981 - val_loss: 6.4763 - val_accuracy: 0.7292\n",
      "Epoch 33/300\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 6.4168 - accuracy: 0.7057 - val_loss: 6.2292 - val_accuracy: 0.6823\n",
      "Epoch 34/300\n",
      "125/125 [==============================] - 73s 586ms/step - loss: 6.1521 - accuracy: 0.7024 - val_loss: 5.9364 - val_accuracy: 0.7101\n",
      "Epoch 35/300\n",
      "125/125 [==============================] - 72s 576ms/step - loss: 5.8731 - accuracy: 0.7191 - val_loss: 5.7234 - val_accuracy: 0.6510\n",
      "Epoch 36/300\n",
      "125/125 [==============================] - 72s 572ms/step - loss: 5.6249 - accuracy: 0.7193 - val_loss: 5.4446 - val_accuracy: 0.7083\n",
      "Epoch 37/300\n",
      "125/125 [==============================] - 71s 571ms/step - loss: 5.3763 - accuracy: 0.7098 - val_loss: 5.1651 - val_accuracy: 0.7378\n",
      "Epoch 38/300\n",
      "125/125 [==============================] - 72s 573ms/step - loss: 5.1494 - accuracy: 0.7169 - val_loss: 4.9817 - val_accuracy: 0.7083\n",
      "Epoch 39/300\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 4.9195 - accuracy: 0.7304 - val_loss: 4.7445 - val_accuracy: 0.7292\n",
      "Epoch 40/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 4.7138 - accuracy: 0.7216 - val_loss: 4.5797 - val_accuracy: 0.7031\n",
      "Epoch 41/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 4.5057 - accuracy: 0.7218 - val_loss: 4.4004 - val_accuracy: 0.6979\n",
      "Epoch 42/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 4.3271 - accuracy: 0.7100 - val_loss: 4.2298 - val_accuracy: 0.6997\n",
      "Epoch 43/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 4.1617 - accuracy: 0.7042 - val_loss: 4.1239 - val_accuracy: 0.6458\n",
      "Epoch 44/300\n",
      "125/125 [==============================] - 70s 562ms/step - loss: 3.9813 - accuracy: 0.7180 - val_loss: 3.9524 - val_accuracy: 0.6406\n",
      "Epoch 45/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 3.7877 - accuracy: 0.7405 - val_loss: 3.7282 - val_accuracy: 0.7031\n",
      "Epoch 46/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 3.6589 - accuracy: 0.7248 - val_loss: 3.5830 - val_accuracy: 0.6910\n",
      "Epoch 47/300\n",
      "125/125 [==============================] - 70s 562ms/step - loss: 3.5099 - accuracy: 0.7186 - val_loss: 3.3616 - val_accuracy: 0.7691\n",
      "Epoch 48/300\n",
      "125/125 [==============================] - 71s 566ms/step - loss: 3.3681 - accuracy: 0.7264 - val_loss: 3.4867 - val_accuracy: 0.6372\n",
      "Epoch 49/300\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 3.2468 - accuracy: 0.7280 - val_loss: 3.2785 - val_accuracy: 0.6493\n",
      "Epoch 50/300\n",
      "125/125 [==============================] - 71s 564ms/step - loss: 3.0944 - accuracy: 0.7354 - val_loss: 3.0729 - val_accuracy: 0.6753\n",
      "Epoch 51/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 2.9878 - accuracy: 0.7356 - val_loss: 3.1691 - val_accuracy: 0.5747\n",
      "Epoch 52/300\n",
      "125/125 [==============================] - 70s 559ms/step - loss: 2.8653 - accuracy: 0.7378 - val_loss: 2.8330 - val_accuracy: 0.6892\n",
      "Epoch 53/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 2.7428 - accuracy: 0.7439 - val_loss: 2.7514 - val_accuracy: 0.6667\n",
      "Epoch 54/300\n",
      "125/125 [==============================] - 70s 562ms/step - loss: 2.6448 - accuracy: 0.7393 - val_loss: 2.6011 - val_accuracy: 0.7413\n",
      "Epoch 55/300\n",
      "125/125 [==============================] - 70s 562ms/step - loss: 2.5433 - accuracy: 0.7490 - val_loss: 2.4323 - val_accuracy: 0.7778\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 70s 562ms/step - loss: 2.4440 - accuracy: 0.7569 - val_loss: 2.5314 - val_accuracy: 0.6615\n",
      "Epoch 57/300\n",
      "125/125 [==============================] - 70s 563ms/step - loss: 2.3733 - accuracy: 0.7271 - val_loss: 2.2403 - val_accuracy: 0.8021\n",
      "Epoch 58/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 2.2631 - accuracy: 0.7563 - val_loss: 2.2682 - val_accuracy: 0.7413\n",
      "Epoch 59/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 2.1930 - accuracy: 0.7498 - val_loss: 2.1044 - val_accuracy: 0.7778\n",
      "Epoch 60/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 2.1083 - accuracy: 0.7603 - val_loss: 2.0598 - val_accuracy: 0.7517\n",
      "Epoch 61/300\n",
      "125/125 [==============================] - 70s 559ms/step - loss: 2.0354 - accuracy: 0.7585 - val_loss: 2.0371 - val_accuracy: 0.7292\n",
      "Epoch 62/300\n",
      "125/125 [==============================] - 70s 562ms/step - loss: 1.9635 - accuracy: 0.7646 - val_loss: 1.9348 - val_accuracy: 0.7622\n",
      "Epoch 63/300\n",
      "125/125 [==============================] - 70s 562ms/step - loss: 1.9067 - accuracy: 0.7530 - val_loss: 1.8341 - val_accuracy: 0.7674\n",
      "Epoch 64/300\n",
      "125/125 [==============================] - 70s 562ms/step - loss: 1.8466 - accuracy: 0.7489 - val_loss: 1.8747 - val_accuracy: 0.6354\n",
      "Epoch 65/300\n",
      "125/125 [==============================] - 72s 575ms/step - loss: 1.7697 - accuracy: 0.7732 - val_loss: 1.6827 - val_accuracy: 0.7726\n",
      "Epoch 66/300\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 1.7208 - accuracy: 0.7618 - val_loss: 1.8319 - val_accuracy: 0.6892\n",
      "Epoch 67/300\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 1.6459 - accuracy: 0.7818 - val_loss: 1.6779 - val_accuracy: 0.7170\n",
      "Epoch 68/300\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 1.6118 - accuracy: 0.7691 - val_loss: 1.6226 - val_accuracy: 0.7326\n",
      "Epoch 69/300\n",
      "125/125 [==============================] - 71s 570ms/step - loss: 1.5587 - accuracy: 0.7724 - val_loss: 1.6657 - val_accuracy: 0.7135\n",
      "Epoch 70/300\n",
      "125/125 [==============================] - 70s 562ms/step - loss: 1.5149 - accuracy: 0.7720 - val_loss: 1.4912 - val_accuracy: 0.7882\n",
      "Epoch 71/300\n",
      "125/125 [==============================] - 70s 562ms/step - loss: 1.4514 - accuracy: 0.7811 - val_loss: 1.3976 - val_accuracy: 0.8021\n",
      "Epoch 72/300\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 1.4121 - accuracy: 0.7894 - val_loss: 1.2941 - val_accuracy: 0.8351\n",
      "Epoch 73/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 1.3732 - accuracy: 0.7792 - val_loss: 1.2677 - val_accuracy: 0.8472\n",
      "Epoch 74/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 1.3176 - accuracy: 0.7902 - val_loss: 1.4983 - val_accuracy: 0.6979\n",
      "Epoch 75/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 1.2851 - accuracy: 0.7858 - val_loss: 1.3526 - val_accuracy: 0.7344\n",
      "Epoch 76/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 1.2854 - accuracy: 0.7773 - val_loss: 1.2317 - val_accuracy: 0.7847\n",
      "Epoch 77/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 1.2245 - accuracy: 0.7821 - val_loss: 1.2388 - val_accuracy: 0.7708\n",
      "Epoch 78/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 1.1950 - accuracy: 0.7929 - val_loss: 1.1732 - val_accuracy: 0.7934\n",
      "Epoch 79/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 1.1638 - accuracy: 0.7835 - val_loss: 1.2088 - val_accuracy: 0.7309\n",
      "Epoch 80/300\n",
      "125/125 [==============================] - 70s 557ms/step - loss: 1.1165 - accuracy: 0.8057 - val_loss: 1.0659 - val_accuracy: 0.8229\n",
      "Epoch 81/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 1.0944 - accuracy: 0.7955 - val_loss: 1.9013 - val_accuracy: 0.5781\n",
      "Epoch 82/300\n",
      "125/125 [==============================] - 70s 557ms/step - loss: 1.0756 - accuracy: 0.7927 - val_loss: 1.0838 - val_accuracy: 0.7708\n",
      "Epoch 83/300\n",
      "125/125 [==============================] - 74s 593ms/step - loss: 1.0516 - accuracy: 0.7936 - val_loss: 1.0702 - val_accuracy: 0.7795\n",
      "Epoch 84/300\n",
      "125/125 [==============================] - 71s 571ms/step - loss: 1.0063 - accuracy: 0.7997 - val_loss: 0.8661 - val_accuracy: 0.8715\n",
      "Epoch 85/300\n",
      "125/125 [==============================] - 71s 570ms/step - loss: 1.0113 - accuracy: 0.8018 - val_loss: 1.1495 - val_accuracy: 0.7361\n",
      "Epoch 86/300\n",
      "125/125 [==============================] - 71s 570ms/step - loss: 0.9752 - accuracy: 0.8065 - val_loss: 1.3867 - val_accuracy: 0.6372\n",
      "Epoch 87/300\n",
      "125/125 [==============================] - 72s 572ms/step - loss: 0.9750 - accuracy: 0.7925 - val_loss: 0.8776 - val_accuracy: 0.8212\n",
      "Epoch 88/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 0.9420 - accuracy: 0.7908 - val_loss: 0.9017 - val_accuracy: 0.8177\n",
      "Epoch 89/300\n",
      "125/125 [==============================] - 70s 559ms/step - loss: 0.8916 - accuracy: 0.8231 - val_loss: 0.8513 - val_accuracy: 0.8385\n",
      "Epoch 90/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.8996 - accuracy: 0.8071 - val_loss: 0.8791 - val_accuracy: 0.8142\n",
      "Epoch 91/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.8826 - accuracy: 0.8073 - val_loss: 0.8289 - val_accuracy: 0.8281\n",
      "Epoch 92/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.8392 - accuracy: 0.8285 - val_loss: 0.7795 - val_accuracy: 0.8490\n",
      "Epoch 93/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.8422 - accuracy: 0.8108 - val_loss: 1.1892 - val_accuracy: 0.6823\n",
      "Epoch 94/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 0.8433 - accuracy: 0.8065 - val_loss: 0.7850 - val_accuracy: 0.8229\n",
      "Epoch 95/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 0.7851 - accuracy: 0.8287 - val_loss: 0.7751 - val_accuracy: 0.8229\n",
      "Epoch 96/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 0.8008 - accuracy: 0.8148 - val_loss: 0.7288 - val_accuracy: 0.8438\n",
      "Epoch 97/300\n",
      "125/125 [==============================] - 74s 588ms/step - loss: 0.7803 - accuracy: 0.8190 - val_loss: 0.6706 - val_accuracy: 0.8715\n",
      "Epoch 98/300\n",
      "125/125 [==============================] - 72s 572ms/step - loss: 0.7500 - accuracy: 0.8382 - val_loss: 0.7593 - val_accuracy: 0.8333\n",
      "Epoch 99/300\n",
      "125/125 [==============================] - 72s 572ms/step - loss: 0.7456 - accuracy: 0.8288 - val_loss: 0.7917 - val_accuracy: 0.7951\n",
      "Epoch 100/300\n",
      "125/125 [==============================] - 71s 569ms/step - loss: 0.7545 - accuracy: 0.8146 - val_loss: 0.7727 - val_accuracy: 0.8194\n",
      "Epoch 101/300\n",
      "125/125 [==============================] - 71s 570ms/step - loss: 0.7341 - accuracy: 0.8284 - val_loss: 0.9263 - val_accuracy: 0.7465\n",
      "Epoch 102/300\n",
      "125/125 [==============================] - 71s 571ms/step - loss: 0.7298 - accuracy: 0.8172 - val_loss: 0.6778 - val_accuracy: 0.8576\n",
      "Epoch 103/300\n",
      "125/125 [==============================] - 72s 573ms/step - loss: 0.7016 - accuracy: 0.8348 - val_loss: 0.5638 - val_accuracy: 0.8976\n",
      "Epoch 104/300\n",
      "125/125 [==============================] - 72s 573ms/step - loss: 0.6620 - accuracy: 0.8600 - val_loss: 0.5630 - val_accuracy: 0.9062\n",
      "Epoch 105/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.6614 - accuracy: 0.8587 - val_loss: 0.5687 - val_accuracy: 0.8889\n",
      "Epoch 106/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 0.6518 - accuracy: 0.8588 - val_loss: 0.5508 - val_accuracy: 0.9028\n",
      "Epoch 107/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 0.6204 - accuracy: 0.8794 - val_loss: 0.5443 - val_accuracy: 0.9045\n",
      "Epoch 108/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 0.6396 - accuracy: 0.8622 - val_loss: 0.5425 - val_accuracy: 0.9080\n",
      "Epoch 109/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.6260 - accuracy: 0.8753 - val_loss: 0.5325 - val_accuracy: 0.9132\n",
      "Epoch 110/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.6205 - accuracy: 0.8692 - val_loss: 0.5375 - val_accuracy: 0.9028\n",
      "Epoch 111/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.6154 - accuracy: 0.8739 - val_loss: 0.5942 - val_accuracy: 0.8785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/300\n",
      "125/125 [==============================] - 70s 558ms/step - loss: 0.6103 - accuracy: 0.8725 - val_loss: 0.5090 - val_accuracy: 0.9201\n",
      "Epoch 113/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 0.6002 - accuracy: 0.8868 - val_loss: 0.5783 - val_accuracy: 0.8993\n",
      "Epoch 114/300\n",
      "125/125 [==============================] - 70s 559ms/step - loss: 0.5993 - accuracy: 0.8794 - val_loss: 0.5067 - val_accuracy: 0.9271\n",
      "Epoch 115/300\n",
      "125/125 [==============================] - 70s 559ms/step - loss: 0.5818 - accuracy: 0.8909 - val_loss: 0.5222 - val_accuracy: 0.9184\n",
      "Epoch 116/300\n",
      "125/125 [==============================] - 70s 559ms/step - loss: 0.5969 - accuracy: 0.8763 - val_loss: 0.5316 - val_accuracy: 0.9028\n",
      "Epoch 117/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.6032 - accuracy: 0.8731 - val_loss: 0.5073 - val_accuracy: 0.9028\n",
      "Epoch 118/300\n",
      "125/125 [==============================] - 70s 557ms/step - loss: 0.5890 - accuracy: 0.8867 - val_loss: 0.5063 - val_accuracy: 0.9167\n",
      "Epoch 119/300\n",
      "125/125 [==============================] - 70s 559ms/step - loss: 0.5794 - accuracy: 0.8854 - val_loss: 0.5354 - val_accuracy: 0.8976\n",
      "Epoch 120/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.5926 - accuracy: 0.8802 - val_loss: 0.5897 - val_accuracy: 0.8646\n",
      "Epoch 121/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.5791 - accuracy: 0.8884 - val_loss: 0.5228 - val_accuracy: 0.9097\n",
      "Epoch 122/300\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.5827 - accuracy: 0.8821 - val_loss: 0.5348 - val_accuracy: 0.9010\n",
      "Epoch 123/300\n",
      "125/125 [==============================] - 70s 559ms/step - loss: 0.5605 - accuracy: 0.8880 - val_loss: 0.5231 - val_accuracy: 0.9010\n",
      "Epoch 124/300\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 0.5833 - accuracy: 0.8830 - val_loss: 0.5142 - val_accuracy: 0.9097\n",
      "Epoch 125/300\n",
      "125/125 [==============================] - 70s 558ms/step - loss: 0.5727 - accuracy: 0.8884 - val_loss: 0.5021 - val_accuracy: 0.9184\n",
      "Epoch 126/300\n",
      "125/125 [==============================] - 71s 570ms/step - loss: 0.5607 - accuracy: 0.8947 - val_loss: 0.5035 - val_accuracy: 0.9236\n",
      "Epoch 127/300\n",
      "125/125 [==============================] - 73s 583ms/step - loss: 0.5540 - accuracy: 0.8956 - val_loss: 0.5014 - val_accuracy: 0.9201\n",
      "Epoch 128/300\n",
      "125/125 [==============================] - 91s 724ms/step - loss: 0.5745 - accuracy: 0.8839 - val_loss: 0.5076 - val_accuracy: 0.9167\n",
      "Epoch 129/300\n",
      "125/125 [==============================] - 76s 603ms/step - loss: 0.5487 - accuracy: 0.8946 - val_loss: 0.5081 - val_accuracy: 0.9184\n",
      "Epoch 130/300\n",
      "125/125 [==============================] - 85s 680ms/step - loss: 0.5559 - accuracy: 0.8988 - val_loss: 0.4982 - val_accuracy: 0.9253\n",
      "Epoch 131/300\n",
      "125/125 [==============================] - 86s 691ms/step - loss: 0.5628 - accuracy: 0.8838 - val_loss: 0.4938 - val_accuracy: 0.9253\n",
      "Epoch 132/300\n",
      "125/125 [==============================] - 86s 685ms/step - loss: 0.5558 - accuracy: 0.8901 - val_loss: 0.5044 - val_accuracy: 0.9167\n",
      "Epoch 133/300\n",
      "125/125 [==============================] - 80s 640ms/step - loss: 0.5614 - accuracy: 0.8907 - val_loss: 0.4989 - val_accuracy: 0.9271\n",
      "Epoch 134/300\n",
      "125/125 [==============================] - 119s 949ms/step - loss: 0.5503 - accuracy: 0.8957 - val_loss: 0.4909 - val_accuracy: 0.9271\n",
      "Epoch 135/300\n",
      "125/125 [==============================] - 130s 1s/step - loss: 0.5489 - accuracy: 0.9015 - val_loss: 0.4958 - val_accuracy: 0.9271\n",
      "Epoch 136/300\n",
      "125/125 [==============================] - 78s 628ms/step - loss: 0.5592 - accuracy: 0.8950 - val_loss: 0.5098 - val_accuracy: 0.9097\n",
      "Epoch 137/300\n",
      "125/125 [==============================] - 58s 461ms/step - loss: 0.5645 - accuracy: 0.8898 - val_loss: 0.4939 - val_accuracy: 0.9236\n",
      "Epoch 138/300\n",
      "125/125 [==============================] - 52s 415ms/step - loss: 0.5582 - accuracy: 0.8903 - val_loss: 0.4948 - val_accuracy: 0.9288\n",
      "Epoch 139/300\n",
      "125/125 [==============================] - 61s 486ms/step - loss: 0.5396 - accuracy: 0.9035 - val_loss: 0.4940 - val_accuracy: 0.9253\n",
      "Epoch 140/300\n",
      "125/125 [==============================] - 54s 427ms/step - loss: 0.5450 - accuracy: 0.9067 - val_loss: 0.4998 - val_accuracy: 0.9271\n",
      "Epoch 141/300\n",
      "125/125 [==============================] - 44s 351ms/step - loss: 0.5516 - accuracy: 0.8881 - val_loss: 0.4975 - val_accuracy: 0.9253\n",
      "Epoch 142/300\n",
      "125/125 [==============================] - 46s 368ms/step - loss: 0.5409 - accuracy: 0.8984 - val_loss: 0.4962 - val_accuracy: 0.9236\n",
      "Epoch 143/300\n",
      "125/125 [==============================] - 54s 434ms/step - loss: 0.5407 - accuracy: 0.8999 - val_loss: 0.4934 - val_accuracy: 0.9288\n",
      "Epoch 144/300\n",
      "125/125 [==============================] - 52s 414ms/step - loss: 0.5624 - accuracy: 0.8843 - val_loss: 0.4927 - val_accuracy: 0.9288\n",
      "Epoch 145/300\n",
      "125/125 [==============================] - 50s 403ms/step - loss: 0.5602 - accuracy: 0.8893 - val_loss: 0.4995 - val_accuracy: 0.9236\n",
      "Epoch 146/300\n",
      "125/125 [==============================] - 48s 387ms/step - loss: 0.5417 - accuracy: 0.9071 - val_loss: 0.4971 - val_accuracy: 0.9236\n",
      "Epoch 147/300\n",
      "125/125 [==============================] - 81s 652ms/step - loss: 0.5473 - accuracy: 0.8988 - val_loss: 0.4988 - val_accuracy: 0.9236\n",
      "Epoch 148/300\n",
      "125/125 [==============================] - 99s 774ms/step - loss: 0.5468 - accuracy: 0.9104 - val_loss: 0.4914 - val_accuracy: 0.9271\n",
      "Epoch 149/300\n",
      "125/125 [==============================] - 50s 397ms/step - loss: 0.5578 - accuracy: 0.8906 - val_loss: 0.5015 - val_accuracy: 0.9219\n",
      "Epoch 150/300\n",
      "125/125 [==============================] - 46s 370ms/step - loss: 0.5491 - accuracy: 0.9005 - val_loss: 0.5006 - val_accuracy: 0.9219\n",
      "Epoch 151/300\n",
      "125/125 [==============================] - 48s 385ms/step - loss: 0.5554 - accuracy: 0.8988 - val_loss: 0.4847 - val_accuracy: 0.9306\n",
      "Epoch 152/300\n",
      "125/125 [==============================] - 43s 344ms/step - loss: 0.5720 - accuracy: 0.8876 - val_loss: 0.4948 - val_accuracy: 0.9236\n",
      "Epoch 153/300\n",
      "125/125 [==============================] - 54s 429ms/step - loss: 0.5431 - accuracy: 0.9020 - val_loss: 0.4897 - val_accuracy: 0.9271\n",
      "Epoch 154/300\n",
      "125/125 [==============================] - 50s 396ms/step - loss: 0.5553 - accuracy: 0.8996 - val_loss: 0.5005 - val_accuracy: 0.9236\n",
      "Epoch 155/300\n",
      "125/125 [==============================] - 46s 371ms/step - loss: 0.5540 - accuracy: 0.8979 - val_loss: 0.4956 - val_accuracy: 0.9253\n",
      "Epoch 156/300\n",
      "125/125 [==============================] - 43s 346ms/step - loss: 0.5642 - accuracy: 0.8899 - val_loss: 0.4993 - val_accuracy: 0.9236\n",
      "Epoch 157/300\n",
      "125/125 [==============================] - 46s 363ms/step - loss: 0.5468 - accuracy: 0.8974 - val_loss: 0.5051 - val_accuracy: 0.9219\n",
      "Epoch 158/300\n",
      "125/125 [==============================] - 55s 421ms/step - loss: 0.5473 - accuracy: 0.8941 - val_loss: 0.4896 - val_accuracy: 0.9271\n",
      "Epoch 159/300\n",
      "125/125 [==============================] - 48s 385ms/step - loss: 0.5412 - accuracy: 0.9048 - val_loss: 0.4989 - val_accuracy: 0.9253\n",
      "Epoch 160/300\n",
      "125/125 [==============================] - 51s 401ms/step - loss: 0.5540 - accuracy: 0.8968 - val_loss: 0.4920 - val_accuracy: 0.9288\n",
      "Epoch 161/300\n",
      "125/125 [==============================] - 46s 370ms/step - loss: 0.5526 - accuracy: 0.8963 - val_loss: 0.4972 - val_accuracy: 0.9253\n",
      "Epoch 162/300\n",
      "125/125 [==============================] - 55s 438ms/step - loss: 0.5607 - accuracy: 0.8920 - val_loss: 0.4989 - val_accuracy: 0.9253\n",
      "Epoch 163/300\n",
      "125/125 [==============================] - 52s 411ms/step - loss: 0.5570 - accuracy: 0.9010 - val_loss: 0.4891 - val_accuracy: 0.9288\n",
      "Epoch 164/300\n",
      "125/125 [==============================] - 48s 382ms/step - loss: 0.5567 - accuracy: 0.8945 - val_loss: 0.4947 - val_accuracy: 0.9271\n",
      "Epoch 165/300\n",
      "125/125 [==============================] - 51s 411ms/step - loss: 0.5509 - accuracy: 0.8934 - val_loss: 0.4945 - val_accuracy: 0.9253\n",
      "Epoch 166/300\n",
      "125/125 [==============================] - 51s 406ms/step - loss: 0.5755 - accuracy: 0.8875 - val_loss: 0.4990 - val_accuracy: 0.9253\n",
      "Epoch 167/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 51s 406ms/step - loss: 0.5629 - accuracy: 0.8833 - val_loss: 0.4979 - val_accuracy: 0.9236\n",
      "Epoch 168/300\n",
      "125/125 [==============================] - 54s 430ms/step - loss: 0.5516 - accuracy: 0.8972 - val_loss: 0.4917 - val_accuracy: 0.9271\n",
      "Epoch 169/300\n",
      "125/125 [==============================] - 53s 422ms/step - loss: 0.5454 - accuracy: 0.9017 - val_loss: 0.4951 - val_accuracy: 0.9271\n",
      "Epoch 170/300\n",
      "125/125 [==============================] - 50s 396ms/step - loss: 0.5535 - accuracy: 0.8963 - val_loss: 0.4874 - val_accuracy: 0.9271\n",
      "Epoch 171/300\n",
      "125/125 [==============================] - 47s 377ms/step - loss: 0.5540 - accuracy: 0.8964 - val_loss: 0.4997 - val_accuracy: 0.9253\n",
      "Epoch 172/300\n",
      "125/125 [==============================] - 45s 357ms/step - loss: 0.5667 - accuracy: 0.8888 - val_loss: 0.5022 - val_accuracy: 0.9219\n",
      "Epoch 173/300\n",
      "125/125 [==============================] - 52s 414ms/step - loss: 0.5471 - accuracy: 0.8967 - val_loss: 0.4993 - val_accuracy: 0.9236\n",
      "Epoch 174/300\n",
      "125/125 [==============================] - 60s 480ms/step - loss: 0.5541 - accuracy: 0.8951 - val_loss: 0.4954 - val_accuracy: 0.9253\n",
      "Epoch 175/300\n",
      "125/125 [==============================] - 57s 455ms/step - loss: 0.5459 - accuracy: 0.8968 - val_loss: 0.5024 - val_accuracy: 0.9201\n",
      "Epoch 176/300\n",
      "125/125 [==============================] - 52s 412ms/step - loss: 0.5468 - accuracy: 0.8995 - val_loss: 0.4916 - val_accuracy: 0.9288\n",
      "Epoch 177/300\n",
      "125/125 [==============================] - 60s 478ms/step - loss: 0.5540 - accuracy: 0.9032 - val_loss: 0.4992 - val_accuracy: 0.9236\n",
      "Epoch 178/300\n",
      "125/125 [==============================] - 65s 515ms/step - loss: 0.5563 - accuracy: 0.8964 - val_loss: 0.4922 - val_accuracy: 0.9253\n",
      "Epoch 179/300\n",
      "125/125 [==============================] - 50s 398ms/step - loss: 0.5416 - accuracy: 0.8986 - val_loss: 0.4991 - val_accuracy: 0.9236\n",
      "Epoch 180/300\n",
      "125/125 [==============================] - 54s 433ms/step - loss: 0.5441 - accuracy: 0.9000 - val_loss: 0.5007 - val_accuracy: 0.9236\n",
      "Epoch 181/300\n",
      "125/125 [==============================] - 51s 406ms/step - loss: 0.5508 - accuracy: 0.8940 - val_loss: 0.5029 - val_accuracy: 0.9219\n",
      "Epoch 182/300\n",
      "125/125 [==============================] - 51s 407ms/step - loss: 0.5631 - accuracy: 0.8982 - val_loss: 0.4981 - val_accuracy: 0.9236\n",
      "Epoch 183/300\n",
      "125/125 [==============================] - 48s 386ms/step - loss: 0.5460 - accuracy: 0.9012 - val_loss: 0.4950 - val_accuracy: 0.9271\n",
      "Epoch 184/300\n",
      "125/125 [==============================] - 53s 425ms/step - loss: 0.5575 - accuracy: 0.8903 - val_loss: 0.5030 - val_accuracy: 0.9219\n",
      "Epoch 185/300\n",
      "125/125 [==============================] - 51s 411ms/step - loss: 0.5428 - accuracy: 0.9000 - val_loss: 0.4940 - val_accuracy: 0.9271\n",
      "Epoch 186/300\n",
      "125/125 [==============================] - 55s 436ms/step - loss: 0.5467 - accuracy: 0.8983 - val_loss: 0.5022 - val_accuracy: 0.9219\n",
      "Epoch 187/300\n",
      "125/125 [==============================] - 52s 414ms/step - loss: 0.5426 - accuracy: 0.9022 - val_loss: 0.5009 - val_accuracy: 0.9236\n",
      "Epoch 188/300\n",
      "125/125 [==============================] - 50s 403ms/step - loss: 0.5428 - accuracy: 0.9032 - val_loss: 0.5023 - val_accuracy: 0.9219\n",
      "Epoch 189/300\n",
      "125/125 [==============================] - 50s 394ms/step - loss: 0.5485 - accuracy: 0.9033 - val_loss: 0.5023 - val_accuracy: 0.9219\n",
      "Epoch 190/300\n",
      "125/125 [==============================] - 42s 336ms/step - loss: 0.5555 - accuracy: 0.8916 - val_loss: 0.5012 - val_accuracy: 0.9219\n",
      "Epoch 191/300\n",
      "125/125 [==============================] - 51s 405ms/step - loss: 0.5654 - accuracy: 0.8886 - val_loss: 0.4987 - val_accuracy: 0.9253\n",
      "Epoch 192/300\n",
      "125/125 [==============================] - 47s 374ms/step - loss: 0.5526 - accuracy: 0.8922 - val_loss: 0.4961 - val_accuracy: 0.9253\n",
      "Epoch 193/300\n",
      "125/125 [==============================] - 53s 419ms/step - loss: 0.5491 - accuracy: 0.8926 - val_loss: 0.4973 - val_accuracy: 0.9253\n",
      "Epoch 194/300\n",
      "125/125 [==============================] - 50s 398ms/step - loss: 0.5397 - accuracy: 0.9066 - val_loss: 0.4945 - val_accuracy: 0.9271\n",
      "Epoch 195/300\n",
      "125/125 [==============================] - 50s 396ms/step - loss: 0.5553 - accuracy: 0.8907 - val_loss: 0.4959 - val_accuracy: 0.9253\n",
      "Epoch 196/300\n",
      "125/125 [==============================] - 50s 401ms/step - loss: 0.5424 - accuracy: 0.8994 - val_loss: 0.4999 - val_accuracy: 0.9236\n",
      "Epoch 197/300\n",
      "125/125 [==============================] - 52s 412ms/step - loss: 0.5539 - accuracy: 0.9022 - val_loss: 0.4989 - val_accuracy: 0.9236\n",
      "Epoch 198/300\n",
      "125/125 [==============================] - 56s 444ms/step - loss: 0.5478 - accuracy: 0.9038 - val_loss: 0.4979 - val_accuracy: 0.9253\n",
      "Epoch 199/300\n",
      "125/125 [==============================] - 52s 414ms/step - loss: 0.5413 - accuracy: 0.9006 - val_loss: 0.4968 - val_accuracy: 0.9253\n",
      "Epoch 200/300\n",
      "125/125 [==============================] - 38s 303ms/step - loss: 0.5542 - accuracy: 0.8982 - val_loss: 0.4995 - val_accuracy: 0.9236\n",
      "Epoch 201/300\n",
      "125/125 [==============================] - 31s 247ms/step - loss: 0.5557 - accuracy: 0.8935 - val_loss: 0.5006 - val_accuracy: 0.9219\n",
      "Epoch 202/300\n",
      "125/125 [==============================] - 33s 261ms/step - loss: 0.5527 - accuracy: 0.8933 - val_loss: 0.4946 - val_accuracy: 0.9253\n",
      "Epoch 203/300\n",
      "125/125 [==============================] - 32s 256ms/step - loss: 0.5547 - accuracy: 0.8992 - val_loss: 0.4911 - val_accuracy: 0.9253\n",
      "Epoch 204/300\n",
      "125/125 [==============================] - 35s 279ms/step - loss: 0.5276 - accuracy: 0.9142 - val_loss: 0.5014 - val_accuracy: 0.9219\n",
      "Epoch 205/300\n",
      "125/125 [==============================] - 28s 221ms/step - loss: 0.5605 - accuracy: 0.8898 - val_loss: 0.5006 - val_accuracy: 0.9236\n",
      "Epoch 206/300\n",
      "125/125 [==============================] - 26s 210ms/step - loss: 0.5348 - accuracy: 0.9069 - val_loss: 0.4996 - val_accuracy: 0.9236\n",
      "Epoch 207/300\n",
      "125/125 [==============================] - 26s 208ms/step - loss: 0.5394 - accuracy: 0.9075 - val_loss: 0.4989 - val_accuracy: 0.9236\n",
      "Epoch 208/300\n",
      "125/125 [==============================] - 26s 207ms/step - loss: 0.5594 - accuracy: 0.8858 - val_loss: 0.4937 - val_accuracy: 0.9253\n",
      "Epoch 209/300\n",
      "125/125 [==============================] - 26s 208ms/step - loss: 0.5628 - accuracy: 0.8894 - val_loss: 0.5028 - val_accuracy: 0.9201\n",
      "Epoch 210/300\n",
      "125/125 [==============================] - 26s 210ms/step - loss: 0.5551 - accuracy: 0.8984 - val_loss: 0.5022 - val_accuracy: 0.9219\n",
      "Epoch 211/300\n",
      "125/125 [==============================] - 26s 207ms/step - loss: 0.5566 - accuracy: 0.8977 - val_loss: 0.4978 - val_accuracy: 0.9253\n",
      "Epoch 212/300\n",
      "125/125 [==============================] - 31s 248ms/step - loss: 0.5600 - accuracy: 0.8934 - val_loss: 0.4955 - val_accuracy: 0.9271\n",
      "Epoch 213/300\n",
      "125/125 [==============================] - 30s 243ms/step - loss: 0.5598 - accuracy: 0.8943 - val_loss: 0.5030 - val_accuracy: 0.9219\n",
      "Epoch 214/300\n",
      "125/125 [==============================] - 29s 228ms/step - loss: 0.5608 - accuracy: 0.8966 - val_loss: 0.5026 - val_accuracy: 0.9201\n",
      "Epoch 215/300\n",
      "125/125 [==============================] - 29s 228ms/step - loss: 0.5583 - accuracy: 0.8894 - val_loss: 0.5008 - val_accuracy: 0.9253\n",
      "Epoch 216/300\n",
      "125/125 [==============================] - 27s 218ms/step - loss: 0.5467 - accuracy: 0.9002 - val_loss: 0.4965 - val_accuracy: 0.9271\n",
      "Epoch 217/300\n",
      "125/125 [==============================] - 27s 211ms/step - loss: 0.5439 - accuracy: 0.8964 - val_loss: 0.4999 - val_accuracy: 0.9236\n",
      "Epoch 218/300\n",
      "125/125 [==============================] - 28s 221ms/step - loss: 0.5599 - accuracy: 0.8980 - val_loss: 0.4972 - val_accuracy: 0.9253\n",
      "Epoch 219/300\n",
      "125/125 [==============================] - 28s 219ms/step - loss: 0.5617 - accuracy: 0.8915 - val_loss: 0.4974 - val_accuracy: 0.9253\n",
      "Epoch 220/300\n",
      "125/125 [==============================] - 28s 220ms/step - loss: 0.5452 - accuracy: 0.8986 - val_loss: 0.4933 - val_accuracy: 0.9271\n",
      "Epoch 221/300\n",
      "125/125 [==============================] - 28s 225ms/step - loss: 0.5513 - accuracy: 0.9009 - val_loss: 0.5033 - val_accuracy: 0.9219\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 27s 214ms/step - loss: 0.5482 - accuracy: 0.8995 - val_loss: 0.4982 - val_accuracy: 0.9236\n",
      "Epoch 223/300\n",
      "125/125 [==============================] - 29s 233ms/step - loss: 0.5554 - accuracy: 0.9004 - val_loss: 0.4951 - val_accuracy: 0.9271\n",
      "Epoch 224/300\n",
      "125/125 [==============================] - 32s 256ms/step - loss: 0.5527 - accuracy: 0.8994 - val_loss: 0.5029 - val_accuracy: 0.9219\n",
      "Epoch 225/300\n",
      "125/125 [==============================] - 34s 272ms/step - loss: 0.5550 - accuracy: 0.8906 - val_loss: 0.4961 - val_accuracy: 0.9253\n",
      "Epoch 226/300\n",
      "125/125 [==============================] - 30s 240ms/step - loss: 0.5263 - accuracy: 0.9125 - val_loss: 0.5006 - val_accuracy: 0.9219\n",
      "Epoch 227/300\n",
      "125/125 [==============================] - 31s 244ms/step - loss: 0.5506 - accuracy: 0.9021 - val_loss: 0.4981 - val_accuracy: 0.9236\n",
      "Epoch 228/300\n",
      "125/125 [==============================] - 38s 301ms/step - loss: 0.5582 - accuracy: 0.8924 - val_loss: 0.4977 - val_accuracy: 0.9236\n",
      "Epoch 229/300\n",
      "125/125 [==============================] - 34s 270ms/step - loss: 0.5749 - accuracy: 0.8756 - val_loss: 0.5007 - val_accuracy: 0.9219\n",
      "Epoch 230/300\n",
      "125/125 [==============================] - 38s 304ms/step - loss: 0.5464 - accuracy: 0.9030 - val_loss: 0.4922 - val_accuracy: 0.9271\n",
      "Epoch 231/300\n",
      "125/125 [==============================] - 31s 247ms/step - loss: 0.5527 - accuracy: 0.8982 - val_loss: 0.4980 - val_accuracy: 0.9253\n",
      "Epoch 232/300\n",
      "125/125 [==============================] - 35s 279ms/step - loss: 0.5545 - accuracy: 0.8922 - val_loss: 0.4898 - val_accuracy: 0.9288\n",
      "Epoch 233/300\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 0.5456 - accuracy: 0.8980 - val_loss: 0.5004 - val_accuracy: 0.9219\n",
      "Epoch 234/300\n",
      "125/125 [==============================] - 33s 259ms/step - loss: 0.5543 - accuracy: 0.9020 - val_loss: 0.4994 - val_accuracy: 0.9236\n",
      "Epoch 235/300\n",
      "125/125 [==============================] - 31s 250ms/step - loss: 0.5537 - accuracy: 0.8993 - val_loss: 0.5048 - val_accuracy: 0.9201\n",
      "Epoch 236/300\n",
      "125/125 [==============================] - 33s 265ms/step - loss: 0.5657 - accuracy: 0.8875 - val_loss: 0.5027 - val_accuracy: 0.9219\n",
      "Epoch 237/300\n",
      "125/125 [==============================] - 32s 254ms/step - loss: 0.5449 - accuracy: 0.8997 - val_loss: 0.4958 - val_accuracy: 0.9253\n",
      "Epoch 238/300\n",
      "125/125 [==============================] - 27s 214ms/step - loss: 0.5647 - accuracy: 0.8913 - val_loss: 0.4966 - val_accuracy: 0.9253\n",
      "Epoch 239/300\n",
      "125/125 [==============================] - 26s 210ms/step - loss: 0.5410 - accuracy: 0.9029 - val_loss: 0.5024 - val_accuracy: 0.9219\n",
      "Epoch 240/300\n",
      "125/125 [==============================] - 27s 213ms/step - loss: 0.5448 - accuracy: 0.9025 - val_loss: 0.4863 - val_accuracy: 0.9288\n",
      "Epoch 241/300\n",
      "125/125 [==============================] - 26s 207ms/step - loss: 0.5290 - accuracy: 0.9083 - val_loss: 0.5018 - val_accuracy: 0.9201\n",
      "Epoch 242/300\n",
      "125/125 [==============================] - 30s 238ms/step - loss: 0.5586 - accuracy: 0.8927 - val_loss: 0.4993 - val_accuracy: 0.9236\n",
      "Epoch 243/300\n",
      "125/125 [==============================] - 31s 245ms/step - loss: 0.5547 - accuracy: 0.8965 - val_loss: 0.4971 - val_accuracy: 0.9253\n",
      "Epoch 244/300\n",
      "125/125 [==============================] - 30s 237ms/step - loss: 0.5553 - accuracy: 0.8954 - val_loss: 0.4997 - val_accuracy: 0.9253\n",
      "Epoch 245/300\n",
      "125/125 [==============================] - 28s 221ms/step - loss: 0.5591 - accuracy: 0.8900 - val_loss: 0.5005 - val_accuracy: 0.9236\n",
      "Epoch 246/300\n",
      "125/125 [==============================] - 29s 229ms/step - loss: 0.5486 - accuracy: 0.8967 - val_loss: 0.4985 - val_accuracy: 0.9236\n",
      "Epoch 247/300\n",
      "125/125 [==============================] - 29s 232ms/step - loss: 0.5438 - accuracy: 0.9038 - val_loss: 0.4947 - val_accuracy: 0.9253\n",
      "Epoch 248/300\n",
      "125/125 [==============================] - 35s 278ms/step - loss: 0.5518 - accuracy: 0.8979 - val_loss: 0.5003 - val_accuracy: 0.9219\n",
      "Epoch 249/300\n",
      "125/125 [==============================] - 27s 217ms/step - loss: 0.5587 - accuracy: 0.8922 - val_loss: 0.5006 - val_accuracy: 0.9236\n",
      "Epoch 250/300\n",
      "125/125 [==============================] - 27s 214ms/step - loss: 0.5698 - accuracy: 0.8844 - val_loss: 0.5011 - val_accuracy: 0.9219\n",
      "Epoch 251/300\n",
      "125/125 [==============================] - 29s 231ms/step - loss: 0.5625 - accuracy: 0.8927 - val_loss: 0.5012 - val_accuracy: 0.9236\n",
      "Epoch 252/300\n",
      "125/125 [==============================] - 27s 215ms/step - loss: 0.5618 - accuracy: 0.8923 - val_loss: 0.4887 - val_accuracy: 0.9323\n",
      "Epoch 253/300\n",
      "125/125 [==============================] - 27s 212ms/step - loss: 0.5651 - accuracy: 0.8953 - val_loss: 0.4968 - val_accuracy: 0.9253\n",
      "Epoch 254/300\n",
      "125/125 [==============================] - 27s 217ms/step - loss: 0.5427 - accuracy: 0.8981 - val_loss: 0.4928 - val_accuracy: 0.9288\n",
      "Epoch 255/300\n",
      "125/125 [==============================] - 30s 235ms/step - loss: 0.5563 - accuracy: 0.8931 - val_loss: 0.4958 - val_accuracy: 0.9236\n",
      "Epoch 256/300\n",
      "125/125 [==============================] - 31s 249ms/step - loss: 0.5467 - accuracy: 0.9008 - val_loss: 0.4941 - val_accuracy: 0.9288\n",
      "Epoch 257/300\n",
      "125/125 [==============================] - 40s 318ms/step - loss: 0.5358 - accuracy: 0.9059 - val_loss: 0.4918 - val_accuracy: 0.9288\n",
      "Epoch 258/300\n",
      "125/125 [==============================] - 39s 309ms/step - loss: 0.5507 - accuracy: 0.8906 - val_loss: 0.4978 - val_accuracy: 0.9253\n",
      "Epoch 259/300\n",
      "125/125 [==============================] - 36s 282ms/step - loss: 0.5432 - accuracy: 0.8998 - val_loss: 0.5028 - val_accuracy: 0.9219\n",
      "Epoch 260/300\n",
      "125/125 [==============================] - 39s 312ms/step - loss: 0.5448 - accuracy: 0.8979 - val_loss: 0.4953 - val_accuracy: 0.9271\n",
      "Epoch 261/300\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.5547 - accuracy: 0.8932 - val_loss: 0.4995 - val_accuracy: 0.9236\n",
      "Epoch 262/300\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.5489 - accuracy: 0.8990 - val_loss: 0.4979 - val_accuracy: 0.9236\n",
      "Epoch 263/300\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.5451 - accuracy: 0.9087 - val_loss: 0.4991 - val_accuracy: 0.9236\n",
      "Epoch 264/300\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.5672 - accuracy: 0.8908 - val_loss: 0.4894 - val_accuracy: 0.9323\n",
      "Epoch 265/300\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.5426 - accuracy: 0.9015 - val_loss: 0.4976 - val_accuracy: 0.9236\n",
      "Epoch 266/300\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 0.5418 - accuracy: 0.9015 - val_loss: 0.4981 - val_accuracy: 0.9253\n",
      "Epoch 267/300\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.5369 - accuracy: 0.9021 - val_loss: 0.4934 - val_accuracy: 0.9236\n",
      "Epoch 268/300\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.5624 - accuracy: 0.8984 - val_loss: 0.4983 - val_accuracy: 0.9219\n",
      "Epoch 269/300\n",
      "125/125 [==============================] - 26s 204ms/step - loss: 0.5394 - accuracy: 0.9007 - val_loss: 0.4990 - val_accuracy: 0.9236\n",
      "Epoch 270/300\n",
      "125/125 [==============================] - 26s 205ms/step - loss: 0.5451 - accuracy: 0.8980 - val_loss: 0.5012 - val_accuracy: 0.9219\n",
      "Epoch 271/300\n",
      "125/125 [==============================] - 29s 230ms/step - loss: 0.5708 - accuracy: 0.8829 - val_loss: 0.4985 - val_accuracy: 0.9253\n",
      "Epoch 272/300\n",
      "125/125 [==============================] - 26s 206ms/step - loss: 0.5520 - accuracy: 0.8903 - val_loss: 0.4956 - val_accuracy: 0.9253\n",
      "Epoch 273/300\n",
      "125/125 [==============================] - 26s 207ms/step - loss: 0.5445 - accuracy: 0.8949 - val_loss: 0.4961 - val_accuracy: 0.9288\n",
      "Epoch 274/300\n",
      "125/125 [==============================] - 26s 206ms/step - loss: 0.5400 - accuracy: 0.9039 - val_loss: 0.4978 - val_accuracy: 0.9236\n",
      "Epoch 275/300\n",
      "125/125 [==============================] - 26s 207ms/step - loss: 0.5738 - accuracy: 0.8881 - val_loss: 0.4927 - val_accuracy: 0.9253\n",
      "Epoch 276/300\n",
      "125/125 [==============================] - 26s 207ms/step - loss: 0.5568 - accuracy: 0.8947 - val_loss: 0.5047 - val_accuracy: 0.9201\n",
      "Epoch 277/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 27s 215ms/step - loss: 0.5679 - accuracy: 0.8875 - val_loss: 0.4975 - val_accuracy: 0.9253\n",
      "Epoch 278/300\n",
      "125/125 [==============================] - 26s 208ms/step - loss: 0.5583 - accuracy: 0.8965 - val_loss: 0.4929 - val_accuracy: 0.9236\n",
      "Epoch 279/300\n",
      "125/125 [==============================] - 26s 209ms/step - loss: 0.5351 - accuracy: 0.9085 - val_loss: 0.4982 - val_accuracy: 0.9219\n",
      "Epoch 280/300\n",
      "125/125 [==============================] - 26s 209ms/step - loss: 0.5425 - accuracy: 0.8990 - val_loss: 0.5024 - val_accuracy: 0.9219\n",
      "Epoch 281/300\n",
      "125/125 [==============================] - 26s 208ms/step - loss: 0.5488 - accuracy: 0.9030 - val_loss: 0.5013 - val_accuracy: 0.9236\n",
      "Epoch 282/300\n",
      "125/125 [==============================] - 31s 249ms/step - loss: 0.5371 - accuracy: 0.9081 - val_loss: 0.5010 - val_accuracy: 0.9253\n",
      "Epoch 283/300\n",
      "125/125 [==============================] - 31s 246ms/step - loss: 0.5479 - accuracy: 0.9043 - val_loss: 0.4975 - val_accuracy: 0.9253\n",
      "Epoch 284/300\n",
      "125/125 [==============================] - 32s 252ms/step - loss: 0.5520 - accuracy: 0.9000 - val_loss: 0.4877 - val_accuracy: 0.9306\n",
      "Epoch 285/300\n",
      "125/125 [==============================] - 30s 237ms/step - loss: 0.5448 - accuracy: 0.9026 - val_loss: 0.4997 - val_accuracy: 0.9236\n",
      "Epoch 286/300\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.5553 - accuracy: 0.8954 - val_loss: 0.4983 - val_accuracy: 0.9253\n",
      "Epoch 287/300\n",
      "125/125 [==============================] - 27s 213ms/step - loss: 0.5480 - accuracy: 0.9015 - val_loss: 0.4935 - val_accuracy: 0.9288\n",
      "Epoch 288/300\n",
      "125/125 [==============================] - 27s 213ms/step - loss: 0.5586 - accuracy: 0.8958 - val_loss: 0.5038 - val_accuracy: 0.9219\n",
      "Epoch 289/300\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.5642 - accuracy: 0.8986 - val_loss: 0.4947 - val_accuracy: 0.9236\n",
      "Epoch 290/300\n",
      "125/125 [==============================] - 29s 228ms/step - loss: 0.5554 - accuracy: 0.8949 - val_loss: 0.4958 - val_accuracy: 0.9253\n",
      "Epoch 291/300\n",
      "125/125 [==============================] - 28s 222ms/step - loss: 0.5606 - accuracy: 0.8838 - val_loss: 0.4900 - val_accuracy: 0.9288\n",
      "Epoch 292/300\n",
      "125/125 [==============================] - 27s 216ms/step - loss: 0.5314 - accuracy: 0.9075 - val_loss: 0.4970 - val_accuracy: 0.9253\n",
      "Epoch 293/300\n",
      "125/125 [==============================] - 28s 221ms/step - loss: 0.5631 - accuracy: 0.8896 - val_loss: 0.4929 - val_accuracy: 0.9271\n",
      "Epoch 294/300\n",
      "125/125 [==============================] - 26s 210ms/step - loss: 0.5525 - accuracy: 0.8954 - val_loss: 0.4910 - val_accuracy: 0.9271\n",
      "Epoch 295/300\n",
      "125/125 [==============================] - 30s 238ms/step - loss: 0.5563 - accuracy: 0.8956 - val_loss: 0.4989 - val_accuracy: 0.9253\n",
      "Epoch 296/300\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.5506 - accuracy: 0.8951 - val_loss: 0.4951 - val_accuracy: 0.9253\n",
      "Epoch 297/300\n",
      "125/125 [==============================] - 27s 217ms/step - loss: 0.5525 - accuracy: 0.9011 - val_loss: 0.4842 - val_accuracy: 0.9288\n",
      "Epoch 298/300\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.5642 - accuracy: 0.8876 - val_loss: 0.5007 - val_accuracy: 0.9236\n",
      "Epoch 299/300\n",
      "125/125 [==============================] - 29s 229ms/step - loss: 0.5676 - accuracy: 0.8951 - val_loss: 0.4993 - val_accuracy: 0.9236\n",
      "Epoch 300/300\n",
      "125/125 [==============================] - 28s 223ms/step - loss: 0.5603 - accuracy: 0.8965 - val_loss: 0.4986 - val_accuracy: 0.9253\n"
     ]
    }
   ],
   "source": [
    "history = vgg_lite_model.fit(train_generator, steps_per_epoch = training_samples // batch_size,\n",
    "                                  epochs = epochs, validation_data = validation_generator, \n",
    "                                  validation_steps = validation_samples // batch_size,\n",
    "                                  callbacks = [reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-blues",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-despite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Approach\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "input_shape = (img_width, img_height)\n",
    "\n",
    "vgg_lite_model_approach_2 = Sequential([\n",
    "    Conv2D(input_shape = input_shape, filters = 32, kernel_size = (2, 2), padding = 'same', \n",
    "           activation = 'relu', kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 32, kernel_size = (2, 2), padding = 'same', activation = 'relu', \n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Conv2D(filters = 32, kernel_size = (2, 2), padding = 'same', activation = 'relu', \n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 32, kernel_size = (2, 2), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Conv2D(filters = 64, kernel_size = (2, 2), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 64, kernel_size = (2, 2), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Conv2D(filters = 64, kernel_size = (2, 2), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 64, kernel_size = (2, 2), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Conv2D(filters = 128, kernel_size = (2, 2), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 128, kernel_size = (2, 2), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 128, kernel_size = (2, 2), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "    \n",
    "    Conv2D(filters = 128, kernel_size = (2, 2), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 128, kernel_size = (2, 2), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    Conv2D(filters = 128, kernel_size = (2, 2), padding = 'same', activation = 'relu',\n",
    "           kernel_initializer = 'he_uniform', kernel_regularizer = l2(l = 0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2, 2), strides = 2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(units = 1024, activation = 'relu', kernel_initializer = 'he_uniform'),\n",
    "    Dense(units = 1024, activation = 'relu', kernel_initializer = 'he_uniform'),\n",
    "    Dense(units = 256, activation = 'relu', kernel_initializer = 'he_uniform'),\n",
    "    Dense(units = 1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_lite_model_approach_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(vgg_lite_model_approach_2, to_file='vgg_lite_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(learning_rate = 0.001, momentum = 0.9)\n",
    "#optimizer = RMSprop(learning_rate = 0.0001)\n",
    "vgg_lite_model_approach_2.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 5, verbose = 0,\n",
    "                              mode = 'auto', min_delta = 0.0001, cooldown = 0, min_lr = 0)\n",
    "snapshot_name = 'vgg_lite_model_approach_2'\n",
    "checkpoint = ModelCheckpoint(filepath = snapshot_name + \".{epoch:02d}-{val_accuracy:.2f}.h5\",\n",
    "                             monitor = 'val_accuracy', verbose = 0, save_best_only = True,\n",
    "                             save_weights_only = True, mode = 'auto')\n",
    "\n",
    "history = vgg_lite_model_approach_2.fit(train_generator, steps_per_epoch = training_samples // batch_size,\n",
    "                                  epochs = epochs, validation_data = validation_generator, \n",
    "                                  validation_steps = validation_samples // batch_size,\n",
    "                                  callbacks = [reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-stretch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pending-hurricane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 5. (e)\n",
    "# Model_vgg evaluation\n",
    "test_data_dir = \"Small_set_cats_vs_dogs/Small_set_cats_vs_dogs/test\"\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1. /255\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stone-chance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 5s - loss: 0.5335 - accuracy: 0.9150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5335274338722229, 0.9150000214576721]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_lite_model.evaluate_generator(test_generator, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assured-addition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABbh0lEQVR4nO2dd5gcxZXAf29nc17tKq5yQhICCUkIkUyOJmcM2GCibQw4ncH22Rxnn9MZn7GxsQ3YZBBBJpgMQgQFJKGcs3YVN+c0O3V/VPdO7+zM7mil1Wx4v++bb7qrqruru2fq1Xuv6pUYY1AURVH6LnGxroCiKIoSW1QQKIqi9HFUECiKovRxVBAoiqL0cVQQKIqi9HFUECiKovRxVBD0IUTkOhF5N9b1iAYR+UhEbomyrBGRse3k3y4i/+fZv1RECkSkWkSOEZE1InLqQVe6l9LeuxCRgSKyTkSSDne9lEOHCoIuRkTeFpEHwqRfLCJ7RSS+C64ZtmE0xjxjjDm7o3K9CRFJBH4C/NaT/L/AncaYdGPMMmPMkcaYjzpx7pHOMzzk77CnYIzZB8wFbot1XZTOo4Kg63kCuF5EJCT9BuAZY4w/BnXqS1wMrDfG7PKkjQDWRHNwT2nkxRKr//MzwO0xunaH9JR3GEtUEHQ9/wJygZPdBBHJAS4AnnT2c0XkdRGpFJHFIvJzEfnUU/5sEdkgIhUi8mcRmRet2cSLiNzonldEPnaSVzgmkqud9AtEZLmIlIvIfBE5up3zGRH5pohsEpEqEflvERnjHFcpIrOdHrlb/lYR2SwipSLymogM8eSdJSLrnXv8EyAh1/q6Y4IoE5F3RGRElLd9HjDPOUeSiFQDPue+tzjp20XkTGf7fhF5SUSeFpFK4EYRmSkiS5x72iciDzrndp9hufMMjw/zjGaKyALnee4RkT+FPBMjIneJyFYRKRaR37oNuvO+PnOOqXCezxmeYz8SkV+IyGdALTBaRE5wfkMVzvcJnvI3Oc+wyrne7SF1vdh595UiskVEzvVkj3DqUiUi74pInidvkXPtsO9ERL4sIsuc8xaIyP0h+Sc5v5lyJ/9GJz1FRH4nIjuc+/nUSTtVRApDzhHNO2zvPRwpIu85v819IvIjERkkIrUikuspN01EikQkIdy99liMMfrp4g/wd+BRz/7twHLP/vPOJxWYBBQAnzp5eUAlcBkQD9wNNAG3tHM9A4wNk36je95w5YBjgP3AcdjG8mvAdiCpneu8CmQCRwINwAfAaCALWAt8zSl7OlAMTAOSgD8CH3vusQq4AkgAvgP43XvE9uo3AxOdZ/ATYH5H9+vkLQaubO/5OPd4prN9v/N8L8F2lFKABcANTn46MMvZHumcK76ddzEdmOXUeySwDrgnpC5zgX7AcGCj575vdJ7Dd5zncjVQAfRz8j8CdjrPPh4YCJRhtc144FpnP9cp/2VgDFbInoIVHtOcvJnOuc9y7jsfmOC5zhZgvPM8PgJ+FXKfK4GLIjyDU4GjnPMeDewDLnHyRjjv/lrnHnOBqU7ew8618rG/xxOwv51TgcKQa3T0DiO+ByAD2AN8D0h29o9z8t4EvuG5zu+BP8a6TTnkbVSsK9AXPsBJQDmQ7Ox/BnzH2fY5P9ojPOV/TlAQfBVY4MkTrKDoCkHwF+C/Q47ZAJzSznVO9OwvBX7o2f8d8H/O9mPAbzx56c59j3TucWHIPRYSbBDfAm725MdhG7ER7d2vk7cJOLe95xOmEfk4pPzHwH8BeSHpI+lAEISpzz3AnJC6nOvZ/ybwged97QbEk/85QaH0EfCAJ+8G4POQ6y0AboxQl38BdzvbfwV+H6HcR8BPQur4dkiZz4CvRvkM/s+9FnCf93mEvOM6YEqYvFPpWBB83EEdWt4DVggti1DuauAzZ9sH7AVmRvu+e8pHTUOHAWPMp9je8CUiMgbb+3rWye6P7aUUeA7xbg/x7hv7i2xRi8WOeKl2PidzcIwAvueoz+UiUg4Mc+oQiX2e7bow++nO9hBgh5thjKkGSrC9vXD36H0GI4A/eOpUihUW+VHcUxm2h3cgFITs34ztDa93zC0XRHsiERkvIm+IHRhQCfwPVgOKdL0dtH7eu5znESk/9Leyg9bswHlOInKeiCx0zB/lwPmeugzD9vojsdezXUvwvbpkYDs7bRCR40RkrmNSqQDuiOK6edjeeXt1ao9W77CD99Devb8KTBKRUVhtqcIY83kn69RtUUFw+HgS2/O9HnjH2NEWAEVY9X+op+wwz/Yeb56IiHff2BEv6c7nk4OsYwHwC2NMtueTaox57iDPC7Zn22JDFpE0rBlgF/Yeh3nyhNbPoAC4PaReKcaY+VFcdyW2ET8QWoXkNcZsMsZcCwwAfg285NQ/mtC9fwHWA+OMMZnAjwjxf9D6Xodjn5VLvvM8IuV769DqGXvK7xI7vPNl7IipgcaYbKzZwz13AdZsdMCIdcaOBVZEKPIs8BowzBiTBTwSxXWLgfoIeTVYM6p7fR+2Q+Ul9N209x4KsObMNhhj6oHZ2P/tDcBT4cr1dFQQHD6eBM4EbsWOJALAGNMMvALcLyKpIjIBKzBc/g0cJSKXOH+4bwGDorheoogkez6+MGX20foP8HfgDqcHJyKS5jj6DrRHHY7ngJtEZKrTKP0PsMgYsx17j0eKyGXOPd5F63t8BLhPRI4EEJEsEbkyyuu+ibWHdxoRuV5E+htjAgR7vQGsEA8QoRFxyMD6eKqdd/uNMGV+ICI5IjIM6wN6wZM3ALhLRBKce57o3FM43gTGi8hXRCRe7ACAScAbQCLWvl4E+EXkPOBsz7GPYd/PGSISJyL5Tn2jYSaw3RgTqo24ZAClxph6EZkJfMWT9wxwpohc5dQ5V0SmOs/6ceBBERkiIj4ROd757WwEkp3fZgLWZ9TRPIb23sMbwGARuUfsgIIMETnOk/8k1kx3ESoIlIPBafDmA2nY3pGXO7HO1b3YH9pzWMcrxphi4ErgN1hTyiRgiZvfDmuwphn3c1OYMvcDTzgml6uMMUuwgupPWJPKZuwf4KAxxrwP/Ce2V7oH29O7xslz7/FX2Hsch7U5u8fOwfbEn3fU+tXY0UDR8DowQTwjlDrBucAasSOO/gBcY4ypM8bUAr8APnOe4awwx34f2/BVYQXtC2HKvIr1ryzHCsXHPHmLsM+j2LnWFcaYknCVdNIvwDo9S4D/AC4wxhQbY6qwAnY29t1+Bc/v0DF33IR1hlZgR1qFaheRuA4rrCPxTeABEakCfurUwb3uTqyJ6ntYk99yYIqT/X1gFdbhX4r9DcQZYyqccz6K1Shr8JhLIxDxPTjP5izgQux/cBNwmif/M6zA/6IdYdejkdbmR6U7ICK/BgYZY74WJi8O+6O/zhgz97BXrgciIrcBk4wx98S6LqGIiMGaKzaHybsR6zA/6bBXLEpEZABWaBzjmFF6JSLyIfCsMebRWNelK9CJFt0AR1VNxPZ+jsU6J2/x5J+D7RnWAT/A2jYXHv6a9kyMMX+LdR16K8aY/VhzVa9FRI7FDnu+ONZ16SpUEHQPMrDmoCFYu/3vsOYCl+OxDrdE7Nj8S4wxdYe7korS1xCRJ7DzEe52TEi9EjUNKYqi9HHUWawoitLH6XGmoby8PDNy5MhYV0NRFKVHsXTp0mJjTOh8C6AHCoKRI0eyZMmSWFdDURSlRyEiEYe+qmlIURSlj6OCQFEUpY+jgkBRFKWP0+N8BOFoamqisLCQ+vpeO7ERgOTkZIYOHUpCQu9aE0NRlNjSKwRBYWEhGRkZjBw5EmmzImTvwBhDSUkJhYWFjBo1KtbVURSlF9ErTEP19fXk5ub2WiEAICLk5ub2eq1HUZTDT68QBECvFgIufeEeFUU5/PQaQaAoihKRdW9A6bboyxcshp2Luq4+3QwVBIeA8vJy/vznPx/wceeffz7l5eWHvkJKbFjyD/iiV65b0rOpK4PZN8B7P43+mFe/Bf+649DVoWijPWdT9zTtqiA4BEQSBH6/v93j3nzzTbKzs7uoVr2YQDPUhF2bpXOUF8CeFbBvjT13Uz08djYseRyq94O/EQIBeOwc+PkgmPfb4LGNtcH8D/8b3v8ZNFTbdC9N9VBfAR/9Cp64EPwN8Nkf4C8nwu5lwXLGwL61tj7loUsnA7uXw0PHQFmESaJ15fa7aq89V3tU7YPmpo6eTsc01UN9ZXDf32AbX5dmP9SW2m1jgnUMR3URbP0I/jAFKiKsNVO5G/44HXZ9EV39tn8KJgCb3oN/XgCL/mq/fz4IPnjAlmmoDj6Lyt1QvAFKt4Z/By6f/h6evMT+Zjpi7i9g2dOw+T3Y/AH8Yaq9DkDhEnh4FhQuhZItULTBPqeSLfb3sSOaFVkPjl4xaijW3HvvvWzZsoWpU6eSkJBAcnIyOTk5rF+/no0bN3LJJZdQUFBAfX09d999N7fddhsQDJdRXV3Neeedx0knncT8+fPJz8/n1VdfJSUlJcZ31k2Z/xC8fz98dx1kdmLhMWNg9cvQWA2jToE/HQsBpxH48oPgS4CCRbbRfeuH0P8ImHo9FCyEjCH2+rOc3uIjJ8GASXDqfVDrCKeHpkJqLlz8sG0khh8Hc26Hze9DYw1g4OWbYb2z4uRjZ8OJd8OQY2yjtdDtVAic9iP40g+gvtyaK3Z8ahuoT34Ho0+FI86HhGRbfMNb8Px1cNI9tpG6+GGY6l0VEtsYlm23jdD8h2DQUXDlPyFnpG2gSrfCmNMhd4xtaHcthXFn2XyXPSvBlwgDJlgh9sINkJAC31xoG6/nv2IFwbXPw57l8MUTtkG9eznM/SUsfxZum2sb+jGnBc+7/Fn41zcgMQMaq2DVS/ZewAqTtf+CgB8qd0HJZljzCgyeAmvmQEMVTLwIUvvBxnfsM0/JscdunWe//XWw/RPYudC+7/4T7XMceTK8+xNISIWb3oJtHwfrtOBhmHwZDJsZTKvYBatmWyFiArbDMHCy/Z3s+gLGngGuP6+mGFa/AuucxeCW/AP2r4Oq3TZ9xk0w5w4o2QRPXQINjkCdeKF9R/tW287DDXNsXaZ+BdLywv+uD4IeF4Z6xowZJjTW0Lp165g40a6N8V+vr2Ht7spwh3aaSUMy+dmFR0bM3759OxdccAGrV6/mo48+4stf/jKrV69uGeZZWlpKv379qKur49hjj2XevHnk5ua2EgRjx45lyZIlTJ06lauuuoqLLrqI66+/vs21vPfaZ3nqUtjyIVz2KBwdxdLFDVUw/09w7M2QPsD2sP7hrHQ5/ATYOR/O+R/bSE25xuY3N9o/Zd54+2esK4PMfLjiH/D42TDiJPDXwy7ntzj1elj+NPiSoDlkFdEZN9vGIjkL0vrDsONs2ZyRcP0r8Pa9sOndYPkp19qGYM0cWPWiFQQrX4DynZCYbgWYy4BJMHQGTL4CXrkNqvcG8/KOsI345Mshf5q1k79wXTB/1ClW2AmQP90+U4CENDjlB7YB8tdD1jCYeSvsXWV7++vfsALx9o/hkRMdDagKrnkWPnsIijfaOjY32vMlZUFDBUy4wB4Lwfs49T6r3SSlW02gaq8VninZ9r1N/xqc/D34/FGY+3N7rMTZBrj/RPs+tzkNfcYQyB5uBfbo02DIVPus374XckZB2TZ7L9s/gbQBcOdi+PvpUL0v+ExHnQJVe2wDXudoMYh9B7ljrBBa/pxtuPuNsc+ncheID0acYM995GVw0UP2eb14k30nCak2f/P79nwZgyE5056+aIMVeAv/Yp9zYjp8/FvbYRl+vBX+g6daoXrO/8Dx3+r4Nx8GEVlqjJkRLk81gi5g5syZrcb6P/TQQ8yZMweAgoICNm3aRG5ubqtjRo0axdSpUwGYPn0627dvP1zV7TkYYz9ZQ+3+9o+jEwSLH4N5v7LmlmufgzX/gvhk2yjvnA9xCbaxXvE8FH4O+9fYP9zM28EXbxvgt34IR15qe5pTrrUaA9gGYv4fbcOeN942uo01todctsMev+Qxe41vLrTX9MXDWQ9AUgbEJ8JXZltBs+wp2P4ZfPl3kJgG48+1vfePfwuZQ23jVbPfNvrV+2zPc9VLsOpl+OJJSMqE6TfB0n9Av9HWvFG8ARY9YhvJmiKrAVz3stV6UvtZB+ob37F1/dJ/wNFXw2vfthpXchZc+ohtzN77qW1k4+JhxIm2wXv8HGs6u/ldePFG2+CW74RzfgmJqbDhbXufOSPg6cutEBh0FKTmwda5tr4f/RKSs6Gp1gqOSx6Bo66EBX+yZrb5f7S97ILP7fNPzrb3lzYAitbZz4V/gAFHwrs/to23K3C2uiu5Cpx5P0y4EOJ8VusYcYIVNhc/bDsFGUNg0kVBgXzc7fYd7F9n9z/+Tevf1DXPWSG79lX7u9nyoX0mg6dYzWXLB1ZA5oyEWz6AAROttuVvgDN+arWOD//bPosb5ljN6LSf2N8GwPF3WmFnmuHpK6xQvPAPMK3N6rWHhF4nCNrruR8u0tLSWrY/+ugj3n//fRYsWEBqaiqnnnpq2LkASUlJLds+n4+6Ol2ArA2rXoR3fmxNKGB7kB3R3ASf/802Ohvfsj3rda/B2DMhYxAsftT+eROSbYO17nV73MAjg3/K7OFWgLhcGrJOe78x9o896SI44ry2dRhzhm3kMgcH09I8HQER2yifeLf9uMT54PJHbSN//J22AfzgAdtIuaaKk75jzS6f/xVmfN32NFP72e1lz9gGb+Pb1kbvS7Dnzxjoqfso+Oq/Wtf3a69b4TFosjU/NdVZQXbUFbaugQD8aTqUboFzf201kvN/Cy993Zp1jrne9nan3xg853m/gfX/tr3Z6r2w9jWY8GX7Po6/EyoKrKls8uX2uU//mu2l15U572gqnP87KzhTsq0m9+yVVvC517nZacQDAfj0Qfs7KfjcPoPRp4R/fyOOh8v+bn8Lo06G837d9v2BNZdV77emyLoymHC+TT/qCvt58UYrFK56ytEanrGN/MnfC/b8Bx0FNzoaUe5Y+1yPvSX4u/B5muOk9OD2rR+Er9MhpNcJgliQkZFBVVX4VewqKirIyckhNTWV9evXs3ChLjXcaYo22B7x3lV2v3yntaMmpNoGZeZtQdusy7Z59o951VPWJv6vb9ie1lFX2N7t4kdh6LG2rNcO3n9C9PWaeq39RGLyZdGfK5SckbYHCXD8t2HgUcH6umQPg7N/Htx3y5/6Q/s96uQDu6YvHk64M7gf6meIi4PrXrIN2aDJNu2I8+Abn9lesNvweRk4yX7Aaiuu7f/0n9jvlGzbULqk5Ni85iYYe5btMcc7naUz77ea4VdeDH9vcXHwpe/b7bFndHy/0WiVR13Rfv75/2t/fzkj7GfECe2XT+0HZ/xnx9c9TKggOATk5uZy4oknMnnyZFJSUhg4MNjjOvfcc3nkkUeYOHEiRxxxBLNmzYphTXs4DY6wrdptG4q6Mus03L8e3voP++fzNiYAW+Zax+bYM23jPvsG24ucdIk936CjbU8egoIgORvSB9LtiE+E8WfHuhaW3DFt0/qNPvTX8SXAEee2TRfpPs8CrAO3C5y4hwsVBIeIZ599Nmx6UlISb731Vtg81w+Ql5fH6tWrW9K///3vH/L69VgW/RWW/hPu+CwoCMA6ATe+bQVB0XqbVl7QVhBsm2fLJqZC//HwLc8koeRMuOOT4L4rCPpPaKtZKEovRucRKN0Xf4Md3rd/rR2J4g6tA9uTj08OjrsGOxzR32gdqIGAHfmxd1Vr+3B75DgO/v5HHNr7UJRujmoESvdl1Ut2dAxA4eLWGkH6AGuKKN0a1Agqdlrt4a0f2LLJWTZ99GlERdYw6/gdfeqhuoNehTvU/GBiXgUChrqmZtKS+kbTU1hWyxsr93D7l0Z361hhXaoRiMi5IrJBRDaLyL1h8keIyAcislJEPhKRoV1ZH6Wb8/nf4eVb7XZtqR0+OHiqtdkXft5aEKTmWkFQsAhqi21aeYF1FIIdr731IztaaPDU6K4fnwh3fRHWubu3op7axvZnivd27nxuGZf9ZT71TVHMpI3Ac4t3cuKvP6S+qZk9FXX87eMtBAKdm8u0paia5k4eezgwxnDvy6v41VvrWb83/GCS7kKXCQIR8QEPA+cBk4BrRWRSSLH/BZ40xhwNPAD8sqvqo/QAlv7TTqIq3wlPX2ZDEVz8sB0lU7iktSBIy7MOS3c2ry/JmoYCAbu/6wvrHxh5cutheZ3AGMNFf/qU376zoU3e4u2lrNvTegLjJ5uKeH/tvoO6ZrRs3l/dcaEwGGN4Yv52thTZ4+97ZSX/XrknbNnvv7iCP324iX+v3MOyneU88MbaTtd36Y4yymubWL+3iqcX7uB/3lzPwm2tw4VEM8n1yQXbOeN383h9xW4q6w9BmIwuYN7GIj7dbDspS7aXdlAathZ17l0eCrpSI5gJbDbGbDXGNALPAxeHlJkEONMZmRsmX+krVBfZGbyBJnjju3Yiz1VP2uGJQ46x+3WeP1NqHgyZZrd9iXZ4YUWBneEKdmRR2fbo/QPtUFLTyP6qBhZsCTZYNzy2iF++tY5vPvMFdz+/rFXjdcNjn3PLk0sor21sdZ4P1u3j4bmbo7rmUwu2c9GfPm239/3ait2c+eA85m+xjc3einpu+sfnFJTWsmBLCU3NgYjHzt9Sws9eW8OPXlnFrvI6nvu8gJ++uprqhtZaz9rdlby0tJB/fLa9JS2aRi2ULUXVPLtoJ1uKagBYvauCJdttPKI5X+xqKff3j7dywq8+ZE9F5Hk0zyzawX+9boXRK8t2MePn7/PC4p0HVB9jDJf/ZT6/eXt9m3ou3VHWaS0FoLrBz9Idpby7dh8ZSfEMzEzi8+1lbcrVNvp5eWkh9U3NLN1Ryum/m8fHG4soKK3lnN9/zMrCcpbtLMPfzns8VHSloS4f8EZsKgSOCymzArgM+ANwKZAhIrnGmEMYUUzpEbhhAtztoTODk3YyhwAm2PsHqxEMnATD1tvJYIv+Fpw4BdZsJD4biycMxhhEhM+3lTJlWBZJ8b42ZSpqm3h+8U4yku3SoBv3VVHd4Cc+TvhsczGLt5dS3xSgqKqBq/66gLED0ltNaPzHZ9v5zlnjAWsbf+CNtewoqWXa8ByOHxOcUPbRhv28unw3/3vlFApKa/nvN9bywfr9AGwtqmHSEDsuf3txDQ99uIl+qYncceoY/vjBJgDeWb2XE8bk8cAba5i7oYiHPtjEi0sL+dH5E7h25nC+O3sFRVUN/OzCSRwz3MbfefC9jQBU1fv5zOm1ltQ08uM5q/j15UeTnOBz7mFbSx7AhEEZFJTWYozh5S92sWhrCecfPZjTjhjQcj8rCsqZv6WEMyYOYEh2CulJ8Tz6yVae+7yARJ/tey4vKGdFYTlxAm+u2sP9Fx3JioJyfvGmnck7d30R1xw7jE83F/PW6j388NwJZKcmsmxnGT+es5pTxvenvK6JjzcWAfDQB5t5ZtFO7jlzHOMHZpDgi2NgZrJzrv1MHJzJoKzkljou3l7G0h1l7C6v45aTR5OS4OO1Fbv48ZzV+AOGi6YM4aFr7cTFBn8zxkBjc4C6xuaW84b+llx+8e91PL94J7lpSUwfmUN6UjyLt5WyYEsJD7yxlvLaRo7Kt/6rd9fu41/Ld3HcqH4AvLd2H3VNzWzYV8U3nv6CXeV13HXGOL7r/I66ilh7bL4P/ElEbgQ+BnYBbbpAInIbcBvA8OHDD2f9uoT09HSqq2OnBnZLdswPxpBpbrQBzVy8Y/qPvtrOykzrb/fdWZnZw+x30QbrJL7LE9EzhPmbi7n9qaX8+MsTufeVVfzgnCP41mlj2V5cw9CcFOJ9cfibA1zwp08oKK1rabwCBn7/3kamDMsmYKC+yfbUEn1xLN5exuLtZVTWBXvULy0t5J4zxyEiLNxawo6SWhJ8wvdmL+enF06isKyOFxYX0D8jiflbSjjnyEE8s2gHy3eWc/qEAXy4fj/biq0gaPQHuPO5L9i839rFn1iwnaZmQ05qAu+t3cdpEwbw5iobZ+jVFTaq5dMLd1JZ5+e9tfvITUvkR3NW8+9vn9TS6xWBrcXVfLKpmLz0RK6fNYL/e38TZbVNPP61GTT4A7yxcg+j8tLYVmx78qdNGMBfPtrCsoJyfvTKKgyGF5cWcv+FkxjWL5XN+6t5e81elu0s59dvryc7NYHnb5vFsp3lgG1M3WcDcPNJo3js023MXlJARV0TIpCRFM9TC3fw23fWU1ZrzT7D+6XxjVPH8OaqPST4hD9+5Rge/WQbKwrKSfAJu8rr2FVex3dnr6Cirglj4DeXH82FU4Zwy5NLuGRqPr+7agqrd1WQnOBrEXB7Kuo55bdzGZWXxqZ91Rw7sh/D+6Xy4tICThiTS0ZyAs9+voPaxmaGZKXw6eZi3vj2SQzNSaHBH+AHL61k8/5qXr/zROJ9cRRVNfDyF4UYA8XVDcwc1Y9+qYm8sXIP1z+2iGE5KcwanctHG/ZTVtvEzFH9+GRTMSsK7PN5auEO4gRyUhPYVW61osc/3cbFU4fwxoo9XD49n6E5qR3/nw6QrhQEu4Bhnv2hTloLxpjdWI0AEUkHLjfGlIeeyBjzN+BvYIPOdVF9lVhSs9+O2Cnd4gQUiyAIBk+F47/Z9nhXMJTvsGEOIlBU1cCN/1xMoz/AH5we9b+W7eLSY/I588F5fPX4kcwYmUOCL46CUvtHbGwOEB8n+AOGxz7dRnxcsPc3JCuZ/75kMgm+OJ5euIN/r7J29ltOGsWjn25jS5FtaP/44WayUxP483XT+Nmra7jrueXk56SwrbiGTY6d/79eX8Oeinp+fP5Erps1nEk/fYcVheVU1DWxeHspq3dV8tcbppOfncIzi3Zy7MgcmpoD/PDlVdzzwnJG56UxKCuZ+Y4Ja2dpLQ9/tJkLjh7MWZMGcvfzy7nxn4vJTUtEBH547gR+9dZ6Xl+xmwunDOGeM8czMDOZ+15ZxR1Pf8GxI3Ooa2rm3vMmcPtTS+mXlsiUodkAfG/2CpLi43jz7pP50ZxV/O+7G8nPTmHDPmuau+nEkUweksVv3lnPjY8vZl9VMKzKUflZrNpVAcCtJ49mRUE5j36yjcn5mQzvl8r04Tm8smwXAzKS+L+rp/Lkgu3MXlJAVkoCj366jS+N609mcgLThtu6XHfcCEbkppKeFM8PXlrJ9BE5+JsDPPThJsYNTKc5YJi3sYiiqgYu/8t8GvxWGF16TD5zlu2iqt7PykJbn59dNInkeB8vLCng3ldWtfrtrI2vpMEf4OTfzGXK0CxmjOzH647Q/XD9fs4+chBPzN9OU3OAMf3T2FJUw3Gj+jF1mH2On2wq5peXHcXAzGRKqhuYt7GILx89mBN++SElNY0k+uJobA4gIjx76yy+N3sF180azn+9tpYzfmc15uzUBL52wsiIv+/O0pWCYDEwTkRGYQXANUCrueoikgeUGmMCwH3A411Yny7j3nvvZdiwYXzrWzYq4P333098fDxz586lrKyMpqYmfv7zn3PxxeoCiUh9pZ1239xgncXesfzpQbMDSREa+eRs+11eYKf4R+DdtXtp9AdI8Al7KmzjtGl/Nb94cx3+gOHxz7bx+GfbSIyPQwTuOn0cf/hgEyNyUzlz4kA+317Ksp3lpCfFM31EDhMGZXDGRCuo0pJ8vLt2H2mJPm44fgSPfrqNMx+0IY1PHpfHf5wzgaOGZvGbK47m0j/Pb+llA1x33HDeWbOPo4dmcf2sEaQk+hiclcyjn2zFNVffc+Y4zjlyEAC/vMxOnKtrbGbR1lLeW7uPn186mfmbS5i/pYRTxvdnytAsGvwBbjl5NLlpiWzZX81TC3dQVtvEsSNzOH3CAH711vqW6wNcO3M4NQ1+fvvOBt5ft48hWcmcNXEgI3NTGZyVwtAcGxp9W3ENV80YyrB+qXzt+JF8smlJixCIE7jjlDEMzExmUFYy1z1qJ/HlpSdSXN3Izy6cxLyNRUwfkcOgrGRuPHEkdz67jP1V9Zx6xABOHp/HK8t28cNzJ3DJMfk0Ngf4j5dW8qM5tmE++0j7vGeO6se5Rw7iuuOGM26g/V2MH5jB2AHpfLKpiDue/qLFJ1Nc3cC9L6+ksTnAXWeMY9LgDM45chDF1Q3kZ6ewvKCcYf1SmTDImuFOnzCA3eV1DMlOYV9lPWt2WyHw7dPHsm5PFe+v28fm/dWcPmEAq3dV8NCHmyitaeSphTs4e9JArjl2OH/+aDNH5WfjixNuOnEUN50YDESZm57EZdPsIMkzJw7khSUFfO2EEWzeX81/nDuBiYMzefNuGz5j1uhc3ly5hxPH5THNMe0darpMEBhj/CJyJ/AO4AMeN8asEZEHgCXGmNeAU4FfiojBmoY6F1/Vy1v3BmPRHCoGHQXn/Spi9tVXX80999zTIghmz57NO++8w1133UVmZibFxcXMmjWLiy66qFuPJY4pDZXWARyf5AgCr0YQhSBwY8/76yDR9gJXFJZzzLBsXl+5h1eX7eLCKUN4b+0+hvdL5Uvj83h64U6G90ulrKaRf6/cw8TBmVQ3NJHoi2NLUQ1H5WdxzpGD+MMHmxiVl859509k8/4qznzwYyYOzuCJr89sVYVpw3M4Kj+LrJQERuQGAw/edcY4vuOYiACmDstmaE4KhWV1XDF9KCsKynng4sn84tLWs6JH909jT0U9Q7KS+fUVR3PS2LYhDFISfTx49dSW/co6a0qZMSKHb58xrlXZ7559BBdMGcLNTyzm+lkjGJ2XRnJCHKdPGMCs0UGfxS0nj+acIwfx+/c3csKYPOLihP+75hhSEnwMzAwGRzx2pLVrnzg2j+SEOOqbAvzw3An44mixo58wJpdpw7P5Ymc5P7/kKD5Yt4/pI3KY4RwLcMr4/sTHCU3NhvED07nw6CEMzEzmeKdOlx6TD1j/xPo9VVx8jF2DIjUxnkdumN7qHqcMywbgrEmDGJiZxPvr9rf0tD9Yv5+zJg1sZW9/6mbrtqxvaibO89985Prp+OIEX5xgjOFLv53LvooG7jhlDNUNft5ft4+axmbOnTyI40b145dvrW/RIG4/ZQzThudw2gTP77YdLpgymBeWFHDu5EFMH9GvTf6Y/ult3uWhpkt9BMaYN4E3Q9J+6tl+CXipK+twODjmmGPYv38/u3fvpqioiJycHAYNGsR3vvMdPv74Y+Li4ti1axf79u1j0KBBsa5u96Shys7sTRsFxZuCph6wwiE52y7O0pEgAEhK5/fvbeRPczdz1YyhzF5SSEZyfIsD9usnjmLi4AyeZicnjMnlyhnD+NYzX3DX6WM5d/Ig9lc18KXfzOW0CQM4YlAG+dkpHOOYIcYOyOCiKUOYMbJtz0xEeOrmoHD42w3T2VNRz1ePH9GqAyAiXHfcCP69aje/veLoiJ2DUXlpfLa5hBuOH8nJ4/qHLRPKzFG5HJWfxdlHhv+djR+Ywcc/OK3lmkt/chapiW0d5cP6pfLgVVNb9qc6DawxhvSkeKob/C2CICXRx+kTBrB2dyV3nDK6zb3+6vKj+WJHGedOHsS5k9vWKyM5gekjcli0rZTxAzOI98Vxwpig0EvwxXHVDGtlPtoxTXWEL044/6jB/OOz7RwxKINrZw6nttHPlTOGhS3vOsddEuODAypFhDtPG8uu8nrSkuJJS4rnmOHZLC8o54wJA8hNT+LrJ41i/pYSdpbWHnCv/eRx/fno+6cyMi+t48JdRKydxYeednruXcmVV17JSy+9xN69e7n66qt55plnKCoqYunSpSQkJDBy5Miw4acVh/pKG/vn9J/YsMShjWP6QKgvZ19DIq9/spWvnziKOI+tfldDIvnO9vzCBh5eZ00Cs5cUMjAziY//4zRe+WIXT8zfzpUzhrb80acMy2b6iBwW3Hd6SwM2MDOZD79/KnnpifjihA++dwoJvmDD4I4mCUd2amLLdqTGGOAbp47hG6eGCdzm4QjH3HHWpOgD4PVLS+T1b5/UbhlvQ32gM3xFhKE5KRRXNzIiN+i0/PXlR1PfFAgr1MYPzGD8wMh+G7BO6EXbSjliUPvlDoQLjh7SIgi+ctzBDTK5+tjWx3/vrCNYs7uC3HSrISX44jhlfHTCOhyxFALQGwVBjLj66qu59dZbKS4uZt68ecyePZsBAwaQkJDA3Llz2bEjwhqziqWh0s4CTs4Khobwkj4Aijcwe1U5v1teSWNzgP7pSby4pJD/uewoznzwY1YmpZApdeypi+fWk0cjAn+dt5VrZw4nKd7HtTOHc+3M4B/6pTuObzElhDZg+dnBZUJDe4uHiytnDGPSkCzGDkjvuPBh5NqZw2lqbt3oZyQnkJHczkEd8NXjRzAkO6VF+B0Kpg3P5srpQ7nkmPyOCx8gJ43L46RxPTfaaCgqCA4RRx55JFVVVeTn5zN48GCuu+46LrzwQo466ihmzJjBhAkHEN++r+FvtEv+JYWJY+/ijBwqa04GGvnN28FZvt94eikAFSadTKmDpHR+dP5Eymoaqar389XjR4Y9pddO3R1JTvAxfUTXOAcPhq4YtZKaGM9FUzqx/nQ7iAi/vXLKIT1nb0UFwSFk1aqgkzovL48FCxaELadzCEJwQ0eEW9DExREE26qEiYMz+crMYVQ1+PnL3C1s2l/NiWNzqd+TCc1FZGbaxjMnLZH/CXHAKorSFhUESuxpsGO4vRpBc8DQ1BwImmVGnwL717BlDxwzIp0bnF7+tqIaXlxayAVHDyGuPAeqIbdfLoqiRI+uR6DEnnonaJtnRNCf527mjN/NozlgmLthP7cvymXD2U+zu6KxZSw7wDUzh3FUfhbnTR5Eara12eYP7LzTTlH6Ir1GIwiN99EbiSYq42Fly4d2vH/mAdh296wE0xxcgB7CmoYW7yhjV3kdi7eXcu/LK9lX2cA7a2xET+8U++kj+rWMkskaOBgKYWBe73HiKcrhoFdoBMnJyZSUlHS/hvIQYoyhpKSE5OSDGJpxqHnuK3bx9wPhnR/BWz9sneauPOYxDW1yZql+94Xl7Kts4CdfntiS5x3R40XcuQRJ3WuUjaJ0d3qFRjB06FAKCwspKiqKdVW6lOTkZIYO7SZr9wQCdhavv+HAjqsOE6c/xDRUUdfUEv5hd0U9F04Zws0njeLn/7aRKb2moVakZNvvRBUEinIg9ApBkJCQwKhRozouqBw6As5iIIEDXLWrphh8Ca3TWkxDWQQChjW7rfN43IB0Cspqufe8CYgIXz9xFI9/to0hETSCltnFkWYfK4oSll4hCJQY0OwsutJ8AKtDNfvt4jLxIQ15y6ihDB54Yy3/nL8dgD9fN43UpPgWU9B/XjCR7549PvIEr/4T7UplWeHDCCiKEh4VBErn8DuC4EA0AneFMX+dPT7eCcdQXwm+JErq4dnPgytNjemf3iqMhIiQ3l5IhGHHwo/3QFxsZgIrSk9FBYHSOVyNIHAAC5nXFAe3Gyoh3hnd01AFyZk8v7iARn+A526dRVqSr5UQiBoVAopywKggUDpHiyA4ANNQrUcQ1FfY5SYBGqshMZ0vdpQxYVBGq2UcFUXpenrF8FElBjR3wjQUqhG4+BsgPoltxTWM7h/bKIyK0hdRQaB0js4IAu/i8/UVwe2AHxMXz87SWkbFOByvovRFVBAoncOdP9DcjiDYvRxKtgT3vRpBvUcjaG6i0fjwBwyj8nQOgKIcblQQKEH8DfDuf7ZusCPRHMU8gr+dAn+cFtyv8Uz485qGAk3UN9uf4qi8YPgIRVEODyoIlCDLnob5D8Fnf+i4bEemoXDhPmqLIc1Zx9VrGmpuorZFEKhGoCiHGxUESpC9znoKGYM7LtvsmIYijRqqK2ubVlMC/ZwZ4CGmoRq/kJkcT05qQtvjFEXpUlQQKEH221g+LTF72qPFNBRhHkHlrrZpVbshaygkZrQxDdU2xzE0J7XXR5BVlO6ICgIliCsIohkJFMk09MEDsGYOVO62+wnOKCBjbFrmEBtuOsQ0VOOPY2Bm0sHVX1GUTqGCQLE01QVj/kQjCPxhYg0ZA4v+CqtfDmoEGXaJSerK7LrEmfl2cfo2gkAYlNWNQmwrSh9CBYFi8Q7zjCZsRDiNoKHSzhKu3h/UCFKd2cOuYMgcYtcd8JiGTMAKggEZKggUJRaoIFAs3sleUZmGXGexR2i4jX/1vuB2aF5mfhvTUHNTA358DMxUQaAosUAFgWKpLw9uRyUIXGexxzTk9vqr9kFFYetzhWoEnlFDxt9Eo4lnUJb6CBQlFqggUCze4Z6ddRa7vX5/HRStt9umOZgnPkgfyIpiQ21V8HqmuQk/PjUNKUqMUEGgWFoJgih8BG6IiXCCAIJLUrrnqtgFGYNoDAiL9zST0FRFc3Og5RxqGlKU2KGCQLHUlUGcM5krnCAINMNj58DmD+y+axpyYw01+4PmIA8VtfXwwX/bIaUZg1mwtYQSfzIJ0symXUX87eMtNDc10Eg8uWmJXXBjiqJ0hAoCxVJXDqm5gIQ3DdUUQ8FCmHO73Q81Df35OFj2FCQEYwVtYwjl1XWYTe+Cv45dk+/gxSUF1MTZMmtWL2P2BwuJpxk/nVyIRlGUg0YXplEsdWV2RnFtSXhB4KbFOT+ZUEFQstl+G2vuMRLHBn8+R8hO6hubWJ54PNe+mgrs4f+OHAlb4PLPr+Zyp+2/YOrwrrgrRVGiQDUCxVJXBik5tqEPJwhcp28kQRBv7fv7jvsRAYmnNm0YNSQRT4Cq2npK65pJS/Txh2umcvFxE9qcfkT/7EN8Q4qiRIsKAsVSV+4RBGF8BK5PwF0TOFQQiA+Ov5NLl0xmdyCbBZX9aTY+En2Gmro6mvHx+6uncvHUfCQ5u+35fRpsTlFihQoCxVJf7ggCX3SmIX+IIDDNNBlhd0U932+6g182XY2JiyMjUfCZZprwMWVYti2bnNn2/CoIFCVmqCBQLHVlkJwd2TTUohGEmIY8UUgrG6x/YNzM89hi8klJSiLZZ/BJgMSExODw0KQwgiBOBYGixAoVBIrt3TdWt+8jcENKtAgCZx8DgQCYZsrrrSC4dFo+eemJZKYmEWeaSYuHgdmetYiTs9qe36fjFhQlVnSpIBCRc0Vkg4hsFpF7w+QPF5G5IrJMRFaKyPldWR8lAm54iZTsA/ARBENLBPyNYAJUOIJgdF4az9wyixmjBkAgQHaSMHP0gOC5EtOsT8GLT+cQKEqs6DJBICI+4GHgPGAScK2ITAop9hNgtjHmGOAa4M9dVZ8+QUUhLH7swI+rK7ffKTkQFxdBI3BMQY5GUFtX15L16zdXAlBW10xmcjzZqYkcMSiD9JQke66AP6hJAIhAUkbr86tpSFFiRldqBDOBzcaYrcaYRuB54OKQMgZwDcZZQEjISuWAePZq+Pd3bRjoA6HSmRGcPjCyacgfFAQ1DX7W7AwuRP/KIjuHoLSumRG5HhNQnM8OOw00txYE0NZhrKYhRYkZXSkI8oECz36hk+blfuB6ESkE3gS+He5EInKbiCwRkSVFRUXhiigQ7Nn76w/suKIN9rv/BNtgm3CmoaAg+GhDEXEmaBrKS7GzwnaU1jM8NzizGHFGIAWagiYll1A/gZqGFCVmxNpZfC3wT2PMUOB84CkRaVMnY8zfjDEzjDEz+vfvf9gr2WNwh2A2R1hQPhL710FKP0jL69BZXFjRyM//vZaUuKCwePz6owAYMyibr584MniM628I+NsOD00KEQRqGlKUmNGVgmAXMMyzP9RJ83IzMBvAGLMASAbyurBOvRu3sXUjg0ZL0QYYMNHa7uN8VNbW88oXhVTUNdmG/K0fUrVzBQBbS+rZU1FPTpJpOXxwmtUILp02nOkj+gXPG+fDjirytzUNDZ8FiemeuqtpSFFiRVf++xYD40RkFFYAXAN8JaTMTuAM4J8iMhErCNT201ncXnVTXfvlvBhj1w6YfBkAjYE4lmwt4rsbVjBxcCazL0olY9EjuK7dY0b25zdTjqb/Z3HgyhtX8ISaf7z7oYLgjP+E/Onw/LWt664oymGnyzQCY4wfuBN4B1iHHR20RkQeEJGLnGLfA24VkRXAc8CNxhgT/oxKh7gaQVNt9MdU77PDR/vb+D+1zUI8zdxz5jg27K3kHx+uaFU8IzWZq2YMI940gWvFc/0HoVY97xDRUCEBEO9ZkUx9BIoSM7pUHzfGvIl1AnvTfurZXguc2JV16FO0mIYOwFlcvhOAqtRh3PiX+fxvXQAfAW48YSTLC8rZsGkheNtot0H3N0JCGjRWBa/XRiOID7/tEu9ZiEZDTChKzFDDbG/C7VUfiEbgmJHWFPlZuqOMfYl+kn2G7IQAD1b/kM9Ce+reEBMJKY4gaD3HIFi2HdMQtBYE4fIVRTks6L+vN+HrhI/Ase9vLvUDPppMHNkJzVC6hX4lX3BhqEXHKwiSM6GGoEYQOlu4lUYQpsevpiFF6RbEeviocijpjLPYacTXl9hefTM+UnxEXrfY6xdIcCaPReUsDucjUNOQonQHVBD0BnYugn9/L9gD37UU5nwjuJ5wGPzNAT5Ytw9/oxUaa/c3kJLgw08cKfEGGmvCH2gMVO21giBjkE1zA9CFagTSkWkoqf18RVEOCyoIegOPnw2LH7XzAADWvQ4rnoWKgoiH/HP+dm5+Ygnvr7Jl9tUYrj52GEZ8pMYDTZEEQTNsnWe3x5xmv1s0gpCfkzqLFaVHoIKgN+GsF9wSTbQmZEqGvxFWv0JtQxN/+WgL8XHC/A12jp8/LpHrZ43glAmDSE+gHY0gAFs/sgHqhhzjnDckRLVLh85i9REoSndABUFvItQ3ECoItnwIL93Ep5/No6SmkUeun86YHNtA33LaRMYOSCcxIdH6ByIJgkAzbJsHo74UbLwjmYZaaQQd+AjUNKQoMUMFQU9g8WPw+t0dlwudP+CNQlpfCX4rKBZvLCQ/O4UzJg7ghmOtnf+WUyfacm6sIVcQjPoSZA8Pnifgh8pdMGCSZ9nKCM5i7wSzcKYfXwIgkfMVRTksqCDoCWz/FDZ/0HG50PkDNcX2+9Pfw6+GQYU1A60rLOK8yYMQEeKc3ry4Zho3UJwrCK593oaCcPEuUNMiCKIZPhqmxy8S1ArUNKQoMUMFQU+guTF8RNBQmkI0gpr91NQ3wfv3A+Cv3AuAL9DEhVOG2DL+etsYu45md/H6xhpAID4FEjyhpVvCSXgFgTuhLNRZ3IGPAIJ+Ao01pCgxQwVBT8BfH11o6VDTUE0Rv/rbP1p2N+8pAeDrs4YwZVi2c0wD+EKGcQb8VrtITLONu9eWH04j6KyPABwhFNdWiCiKctjQf19PwN8QpUbQ2llcVbqHwL51Lfv7SsoA+NJoz+pg/oa24/kDfruYvasJJKQE8wOOIBBfMHR0S6yhkF5/R/MIwF5btQFFiSkqCHoC7QkCjzmosb61j6CmZA/9fcG08soqAMQ177jnDh294/oIEp2Zw15BENZH0BhM8xKVaShZ/QOKEmNUEPQEmtsRBA2VLZtxza1NQ0kNpRw7KPiKE4zTYHsXrvHXh2gEro+gNigIwpmGJBpncZQagS5KoygxJSpBICKviMiXwy0jqRwG2tMI6itaNuMl0LJdG59NjlQxOTvY6PdLdOIHdagROKahcBqBaxqKiwuadCLGGuog6BzYa6tpSFFiSrQN+5+xq4ttEpFficgRXVgnJRRXEIRbs8cjCLysaRwAQFbN9pa0YRlxwfO1nDtUI/DMIwhrGvKOGnIa/hZn8QEuTAOORqCmIUWJJVEJAmPM+8aY64BpwHbgfRGZLyI3iYh257oat+EOFxHUDScRwuZAvt0o2oCJtw35YKddb2m43XOHmoaM4yNwncXxXkHgaCZx8WF8BKEhJjqYRwCOj0BNQ4oSS6I29YhILnAjcAuwDPgDVjC81yU1U4K4DXeg7RDSQF14jSCQZ5eepLEaSe8P0DJ5rKXhhvAaAVjfg7u4fFjTkK/timhtTEOen1ckQZCgzmJFiTXR+gjmAJ8AqcCFxpiLjDEvGGO+DaR3ZQUVPBpBWz9BRVlx2EOuu+Cs4E5af+c8ToPt1QiaQ30ETmNeXwmJYYaPhptQ5k3zEo1GcPydcMZPw+cpinJYiFYnf8gYMzdchjFmxiGsjxIOVxA0N/Hkgu28vXovz9xyHCJCRVkxOeGOyRuHjeNjgoLAHWrqD3UWh9EIGqsijBpyTUNhRg21iTUUhY9g+Kzw6YqiHDaiNQ1NEpFsd0dEckTkm11TJaUVgUDQHBNoZt6GIuZvKeHvn2zl9qeWUFJa0rp87lgYcSJkDIZ06zAmLc9+O0HnWvsI6iNHAW0xDYULMRFnw1KILyioQp3F3nNpUDlF6bZEKwhuNcaUuzvGmDLg1i6pUW/jsbPh87+Hz3v5FnjvZ+0f7220A01sK7bB4P7nzfW8s2YfS7fsbV1+1Clw05u24XVXEGsxDTW0/na3I60U1jKz2CMovD4Ct3xn1yNQFKVbEK0g8Im4UclARHyAevg6orEWChbB7mXh83cugsIl7Z/DEz+oqamRnaXBmcLTR+QERwK5eBvcjMH2O83RDNwQFM2hzuIwPgLwmIY8PgJ38RsJJwg6MaFMUZSYE+2/823gBRH5q7N/u5OmtEdFof2uLQ2fX1sSbGzDEAgYxN/gRuynsKQKf8CQkRRPgz/Ao1+dQc77/ewYLhevCSZUI3B78/4GqCu3UUnrK1qP2glrGvIIgpZyvuD13PDX7a5ZHMFHoChKzIlWEPwQ2/h/w9l/D3i0S2rUm6jYab/rSu24fF9isKFuqrPrAteWWCeuSGsTDfDAG2tZtXoVLzv7t/xjAZDP/141hbz0JHLSEm2jnphhnbvQusFt0QjyWteruRG2zoWlTmTSSD6ClGz7nejxEbi4jbwvMTiXod2ZxaoRKEp3JdoJZQFjzF+MMVc4n78aY8LMblJaUe4sHl9bCo+eCfN+HcxztYS6Upj9VXj1W60ONcbwz/nbKauqaknzYc0yx43qx/QRzlghfz0keUbwehvcnJGAQNbQ1vXyN0DJ5uB+JB9Bcpb9TsmBi/4EI07ylHN+Ol5tojPDRxVFiTlR/TtFZBzwS2AS0NJ9NMaM7qJ69Q4qXEFQbE0wA48M5tU6o30Cfti5AHJGtDp08/5qwAkL4Zj0E7CyNzvV0/j6G4ImHGjd4E6+HPLGtxUEzY1QsjW4H0kjcAUBwLQb7FrFLuIxDbUc297CNDpqSFG6K9E6i/8B/AXwA6cBTwJPd1Wleg2uj6CuzDpZvQvC13n8Bg2VwWUlHRZstYLi5uPzW9K+d+Zo5v3g1NbXaG6IrBH4EiB/WtveeHsagXcIqFcQhObFeUxD4a7tLRO6rShKtyJaQZBijPkAEGPMDmPM/cCXu65avQTXNOTSEDTztGgELjVFPL1gG4/M2wLAgi0l5GencOLIYCM/NT+dEbkhzuU2GkGYBje0gW5ugNItwf1oNAJobfqRMIIgkrNYfMGlMBVF6XZEa7htcEJQbxKRO4FdaGiJjqkoCEbzhFYaQXN1Ma2azYCfx95bxrbaJI4YmMHCrSWcPmEgvkBQYPRLDiO3/fV2VJDEWa0j0iLx4gSTA6je31oQdTSPoOU84TSChLZpoedS/4CidGui1QjuxsYZuguYDlwPfK2rKtUrMAaq9tqZvi6N1u5f39TMo+8ubXNIXF0xyQlx3PX8Mspqmzh+TG7ryV9hgs61TAhzbfCRbPHexrhqj/0OF+zNWy60F+/1AUSjEXgnnSmK0m3pUBA4k8euNsZUG2MKjTE3GWMuN8YsPAz167k01tiGu9+Y1mnAQx9sIqmxjEbTuuEcEFfJAxdNpqreahBtBUGYxWncCWFuzzxSoxsuxMOQafbb659oz5bfSiNwRw2pRqAoPZ0OBYEzTPSkjsopIbhj6/uNCqY1WI1g9pJC+kkVu0wextNInjAwwOXThzI6L40RuankZ6e0FgTN4QSBqxG4jW6Ehjxc+pGX2u/sYZ5y7TTaEk4jSAjmhWoQbnl1FCtKtybartoyEXkNeBFoMXQbY17pklr1BtyVw7yCoLGamgWPM7a2hJHp9ZTWZzIg3k9zQy2ZUsdt0zPwxQl//9oMGv1OKIfmKDQCX1LHGkE4k9GMm2D0KdB/gqecc3y4VUnDzRR2TUOhZiEI+iY04JyidGuiFQTJQAlwuifNACoIIlFXbr9zRgbTTDNp73yH5xOhNHkiX9SlU1BfT430Z5psJKnBOnDH9Pf44Ts0DTW2Xvc3oiAISU/KtJrEgInhyyVmtD1HexpBe5qImoYUpVsT1T/UGHNTZ04uIudiVzLzAY8aY34Vkv977LwEsM7oAcaY7M5cq9vhmoZSc23Qt4bKVgHkMqWOKvrxa/81nDVlFNN3/gxqitqeJyofQVJwucdoBUFqbvvlwsVACjcvoD2NwD2fmoYUpVsT7czif2A1gFYYY77ezjE+4GHgLKAQWCwirxlj1nqO/46n/LeBY6KvejfH1QiSs+GGObDlQ3jvP1uyfc31HDl8ECUTvsK1J42CvzwM1SGCoGAxrH01uB8qCALN1iHt1Qgirf8bmu7GEQrFbbTDCYKwGkFi6+PaHKMagaJ0d6L9h77h2U4GLgV2d3DMTGCzMWYrgIg8D1wMrI1Q/lqgg+D8PQhXI0jJtn4C7wQuQJrqGD90AONPdqJ09B8PW+fZ0NUJKda+/tiZrc/ZHDJ81NUW4qPxEYSahsKYfiA41yCsIPA4g0PnEahpSFF6LNEGnXvZ83kGuAroaInKfMA7tbbQSWuDiIwARgEfRlOf7o4xhreWrMcgkGRn5+5vCHGYNtW2Du987C027MSvR8LLN4c/cahG4JqaovIRhFw/KTN8uUYnpHRimPmCB+osdsupIFCUbk1n/6HjgAGHsB7XAC9FimgqIrcBtwEMHz78EF62ayiqbmDfvr3UJqTy1b8uxB8wnJxUxPe9hQJNrWfujjgR8qfDrqWwIcJSD20EgasRJB64jyCSIHDXMBh/Ttu8zpiG4uJVEChKNycqjUBEqkSk0v0Ar2PXKGiPXYBngDpDnbRwXAM8F+lExpi/GWNmGGNm9O/fP5oqx5QNe6vIkhpKm1NZuqOMHSU1vLeltm1Bb5x/Ebj+FRh7FmQMtGneyWgQpUYQoUEO9RFEMg3ljYPvrIETvt02r70QE5E0AvURKEq3J1rTUIYxJtPzGW+MebmDwxYD40RklIgkYhv710ILicgEIAdYcKCV765s2FtFJrVUkEZuWiKv33kSCSlhGt7Qlb9SsiFzcNA8Ezr+PtRH4C45eSh9BGDDVocLEucVMqoRKEqvIVqN4FIRyfLsZ4vIJe0dY4zxA3cC7wDrgNnGmDUi8oCIXOQpeg3wvDGmzaiknoQxhjn/eomtBbtZv7eKPF8t9fEZfPX4kQzrl8qc74QxtYQGdQNISAsu/eiuMezi1QhqimHHfLsdn+yZWRxFrCFoXxBEor0w1OEmoIENRaGCQFG6NdH+Q39mjJnj7hhjykXkZ8C/2jvIGPMm8GZI2k9D9u+Psg7dmm17irhw2a28t+8ONjR+mbz4OgaPPYLpZ9igcwnJUWgEYM1FriDw18OEC+CsB+CP0+xwUZcnLoL9a+z2gWgE/SdC0ToYc3r4cu3RKgy1Gz4iCt+EziNQlG5NtNFHw5Xru928pnp4+grYt6YlaeX6TcRLgNKivWzcV0Wm1BCXmo24JhZvPCCXsBpBqu35+xutRpA1DPo5Q0y90Uf3B699QDOLx54BPyuHwUdHf78uYYeP6jwCRenpRCsIlojIgyIyxvk8CLSNo9xXqNwFm9+D7Z9aYeBvZPM2u/Rjc30VDf4AaYHq1gu7iLQdmx9JEIBd2L6pDhKS7bHedQ2g9cxgn3dmcSRnsceZ3NlFYtobNdTuzGIVBIrSnYlWEHwbu3LuC8DzQD3wrXaP6M046wpQuhX++iXM8mfZs2snAGlSx/j+KcQ1N1h7v5fsEXamsUsk0xDY1cy8Q0zj4ls7i1PzgtvxSZ6eeQcawcE0ymFDTHQwWiljkHWAK4rSbYk21lANcG8X16Xn4Izqqd+9huSAn11bV5PYEIAEGJzs55snDYW3aNvQ3/QmrH0NXv2m3Y/kLIbgCmLuMpJxCa19BGl5ULwhWCZa09DBCIJ2NYIIfYqrn4qsLSiK0i2IdtTQeyKS7dnPEZF3uqxW3YWKQvj9ZCje1DrdWWCmZOc6AJavXsPgeKslnDA0iUsmO2abUEGQlNE6xk97GoErCNwycT6rITTVQ00JpPYLHnMgQecijSqKhvZmFke6bmKaNW8pitJtidY0lGeMKXd3jDFlHNqZxd2TvavtusO7QtwhjmkoX+zKXv0pZUaeP5jnd4Z9xodpAL2Nf3s+gpoQQeBLsD6CJy6A345u3QOPJuhcRwvXREPLNSXoZ+jINKQoSrcnWkEQEJGW2A4iMpIw0Uh7HW5Y6MqQCdFNrWcJH5lWzXRXEDRU2147hO/xexv/xDCCIDGSacjxERQutvtef0E0w0c7yo+GcCuOdeQsVhSl2xNtq/Bj4FMRmQcIcDJO7J9eTc1++10ZEmi1sabVbnrDPqh31v09EI0gvh1B0WIa8jiLvT6CUEHQoY8gxLnbGdx1iiWMIFCNQFF6LNE6i98WkRnYxn8ZdiJZXbsH9QbcRd3bCILq1vuBJtjvRNeOViOITw42rK3ynWNaBIFHI/AOH/XOKfBF4yPoKo0goXWeoig9jmgXprkFuBsbOG45MAsbG6gT01N7ENWuRhA0DTX6A3yxvoBZoWXrypwCVUHTUTiNwE0LJyQgjGnIdRbHt278vSuXxcV1HHTukPgIfK2/oWNnsaIo3Z5ou3F3A8cCO4wxp2FXEivvqkp1G1p8BEGN4O01e1m93aMheEfhJKSCCQSFQnvO4NA5BqH5oaOGfAmtYw811cLIk+EnRcF8OEw+As/PRp3FitLjiVYQ1Btj6gFEJMkYsx44ouuq1U1wBUFNUUsP/LlFO0kluPYwAycFt6d+pfVx4YZNug17tBqBd/ho1Z5gucZa6xuId3rkCam2p+720ENxG+qDGj4azkfQQRhqRVG6PdEKgkJnHsG/gPdE5FVgR1dVqttQUxQ0zVTtYdnOMhZsLSE9rjFYpv8Eu47Ad9fD0GOd4xzfQmdMQ3E+a/MPN6Gs0iMImmpbN+rHXA/Xv2SFQ9jzHsKZxeFGDalGoCg9lmidxZc6m/eLyFwgC4iwjFYvIdBsG+P86VC4mIbSAr7zyjbys1OYnOqDUqdcSj8byA2Cyzu2aARhGvu4OCtcwpmNXBJTg8LEO2rIHcUEduSSd85Aar/2I4p25EOIhrAaQQczixVF6fYc8L/XGDPPGPOaMaax49I9mNpSa+/vby1gG7cXsL2klp9dOIl+iU1UGqeR9wZ/SwoRBOE0ArACIpJGAI7/wJmm4ZqXQod9hmoEHeFqAgczfDQ09LT3fOosVpQei3bjIuE25ll2tc1te0qIjxNOGpdHlq+JpqyRGPHZ1bxcEp01B1p68xEa+4TUtpFIW+WHmWsQ2pNvbjywRr2j4aXRENZZrKYhRenpaDcuErW2Ma9IHEAWMG9tIZPzp5GaGA+NNeTmj4VTH7dr/LpEqxH0H9/6uFDcGcdxCe034J3RCA6FIAhrGlJBoCg9FRUEkXCGgG6qzWAGkCRNzBocB//4sl3ha8jU1iOGINjLrymyQiBS3P8b5oRPd3GHlno1g3CN/oFoBIfCRxDWWazDRxWlp6OmoQjUVliNYEOt7eUn0chlmethx6e2QDjTjussri9v3wfQEe56wl6Nwu3JJ3kWuzkgQdBVw0dVI1CUno4KgjAYY3jx01UAPLrcTuL68TmjGV/jiUIabtRPUgY2FBPh4whFyxHn2u9Wo4ScsBb504JpsTINtVqgxtUI9KekKD0V/feGYVlBOXUVxTSYBLbX2oYuvrkBts4LFnJ7/17ifMFRRAcTg//oa9qmFa233/nTg2mRQk6H45DMLA4TYiIuTtclVpQejv57w7C9uIYsqqkkDUMcTSSQULoFKnbakUGNVUSMwp0+0DqaD0YjSEyFyx+DhspgWvU++32wGsGBCI9Qwo0aAmseUtOQovRYVCMIw56KerKkBr9jj2/2JdrVygBGnmi/S7eFPzjdWa/nYFflOuoKmPH14H7+DPudmR9MOyAfwaGYWRzGRwCQ1r/1fApFUXoUqhGEYV9lPcf6aohL7QeVYHxJdoIZwKRLYOPbMPny8AenD7TfB6MRhOOrr9rZxG7oCTiwRj1vHKQPgowhna9DOB8BwC3vQVJm58+rKEpMUUHgpaEKkjLYW1FPblwtKVlDYC/EJSQHI4rmjoX7KyKfI8MVBBFi/nSWpHT7aagKph2IRjB4Cnx/w8HVIdyoIYCMQQd3XkVRYoqahly2fwq/Hgll29lXWU+2VJOZM4AF951OUnIq1DkaQbjlJb24GkFzF0Xg8Db+BzMUtDNImHkEiqL0eFQjcNm50K4AVrSRPRVxpJtqSM5mcFaKHc/vrg7W0fwAVxB4Hb2HEm+Y6YOJG9QZWjQC7T8oSm9C/9EuRdZs0lxRSEV1DUmBOkjJsXleM0+kBWVcXGdxfVcJgoTw24eDcDOLFUXp8ahG4OKM068t3kmGcUb8pGTbb+8M35hrBLE0DUXwESiK0qNRjQDs2gPFGwFoKC0kS5xZvOE0gvaihsJh0AhiaRpyZk2rRqAovQoVBADlO8Fvl58s37udI+KcxepbBIG7JkBSx41gcrY1H537y66pq1cQHO7ZvOFmFiuK0uNR0xC0aAN1yQMYW7WYhxKXQdbw4CxeVyOIJpCcCPx4d8flOkucz5poTCB2zmLVCBSlV6EaAUClbbg/rBkJgC8uDm6d21Yj6MgsdLhoWQxGRw0pinLw9Pl/dE2Dn9UbNwOwgVEAyNCZkJYXLHQgGsHhwBUABxM3qFPX1VFDitIb6fOmoZe/KCSwdiPDfGlkZWZCDTD61NaFXI2gvQXnDyctkURjZRrq8z8bRelV9Pl/9LKd5ZwhFRSbTPaNuRJycuGEO1sXatEIuosgcExDh91HoM5iRemNdKlpSETOFZENIrJZRO6NUOYqEVkrImtE5NmurE84lheUkyeVFJPFhJH5cNp9bU1ALT6C7iYIEtsvd6jR4aOK0ivpMkEgIj7gYeA8YBJwrYhMCikzDrgPONEYcyRwT1fVpxX718Mrt1FWVcu24hqGJVZTShbHjuwXvny30wgOwSIznUGdxYrSK+nKf/RMYLMxZqsxphF4Hrg4pMytwMPGmDIAY8x+Dgfb5sHKF1i3yQ4bHRBXxVnHTmZYvwgNvRtSutsIghiZhtRZrCi9kq4UBPlAgWe/0EnzMh4YLyKfichCETk33IlE5DYRWSIiS4qKig6+Zo01AGws2E+C+EloLCfeDR8dDlcj6DamIXeRGQ0xoSjKwRNrHT8eGAecClwL/F1EskMLGWP+ZoyZYYyZ0b9//4O/apNdkH7LnmJm5AVsmne4aJtadrdRQ65GEKOZxaoRKEqvoisFwS5gmGd/qJPmpRB4zRjTZIzZBmzECoaupakWgO17Szh+YLNNc2MEhaPb+QhiPaFMBYGi9Ca6UhAsBsaJyCgRSQSuAV4LKfMvrDaAiORhTUVbu7BOFkcjiG+s4EyzwKaltaNptGgE3WRCmesb0BATiqIcArrMtmCM8YvIncA7gA943BizRkQeAJYYY15z8s4WkbVAM/ADY0xJ5LMeIhyN4BLfZ0zaMt+m5YyKXF5DTDjXc+cRxNqiqCjKoaRLjczGmDeBN0PSfurZNsB3nc/hwxEEQ+MrwQDf/iK41nA4NMSERecRKEqvpE927Zrq7aihYclWIJAxuP0DWkxD3UUjiHGICfURKEqvok8KgvJKu2hMjqkEJIpVxwbYRjBraNdXLhpiNrNYRw0pSm+kT8YaCjRYjSC+ocyOBHJNHpHIGQHf39T+ENPDSYuP4DA3yKoRKEqvpE9qBOL4CMQ0R+8A7i5CAKxpKC6hYwF2qImLBwTiD7MmoihKl9InNYK45vrgTneZLXwg+BIP/9BRsALgqidh2HGH/9qKonQZfVIQxHsFQXdxAB8I/Y+AARNjc+1JF8XmuoqidBl9UhAkBHq4RjDzVvtRFEU5BPQ9H4ExJNMQ3O8uk8QURVFiRJ8TBM1NDfgIBBN6omlIURTlENLnBEFFZUXrhJ5oGlIURTmE9DlBUF4RKghUI1AUpW/T9wRBqEagpiFFUfo4fU4QVDnhJVpQ05CiKH2cPicIKqusIDCuJtBdFptRFEWJEX1OEBSXldmNtFz7nZgeu8ooiqJ0A/qcICgttz4CSelnE9Q0pChKH6fPCYJKd9RQqiMI1DSkKEofp08JgtpGP3V11XYn1TUN6aghRVH6Nn1KEGwvriWFRrvTYhpSQaAoSt+mTwmCbcU1pLhxhtQ0pCiKAvQxQbBsZxnpcY5GkJxtv1UjUBSlj9NnBIExhnfW7mVMTpzVAjIG2hW3XF+BoihKH6XPCIJ1e6ooKK1jbLbPCoKJF8G3Pu9eS1AqiqLEgD4jCN5duxcRGJaBFQRxPsgdE+tqKYqixJw+s0LZTSeOYuqwbJJXzIaElFhXR1EUpdvQZzSCrJQETj1iADTVqiBQFEXx0GcEQQtNdTpSSFEUxUMfFASqESiKonjpg4KgTgWBoiiKh74nCBprdDaxoiiKh74nCJrqVBAoiqJ4UEGgKIrSx+lbgsAYdRYriqKE0LcEQXMTmGYVBIqiKB76liBoqrHfOo9AURSlhS4VBCJyrohsEJHNInJvmPwbRaRIRJY7n1u6sj401dlv1QgURVFa6LJYQyLiAx4GzgIKgcUi8poxZm1I0ReMMXd2VT1a0SII1FmsKIri0pUawUxgszFmqzGmEXgeuLgLr9cxTbX2WzUCRVGUFrpSEOQDBZ79QictlMtFZKWIvCQiw7qsNruWwvv/ZbdVI1AURWkh1s7i14GRxpijgfeAJ8IVEpHbRGSJiCwpKirq3JUKFsPm9+y2CgJFUZQWulIQ7AK8PfyhTloLxpgSY4yzmjyPAtPDncgY8zdjzAxjzIz+/ft3rjZDjw1uq2lIURSlha4UBIuBcSIySkQSgWuA17wFRGSwZ/ciYF2X1WbQUcFt1QgURVFa6LJRQ8YYv4jcCbwD+IDHjTFrROQBYIkx5jXgLhG5CPADpcCNXVUf4hOD24kqCBRFUVy6dKlKY8ybwJshaT/1bN8H3NeVdWhFah7UFkN88mG7pKIoSnenz6xZDMDN78LK2ZCaG+uaKIqidBv6liDIHQOnHT4FRFEUpScQ6+GjiqIoSoxRQaAoitLHUUGgKIrSx1FBoCiK0sdRQaAoitLHUUGgKIrSx1FBoCiK0sdRQaAoitLHEWNMrOtwQIhIEbCjk4fnAcWHsDqxRO+le6L30j3Re4ERxpiw4Zt7nCA4GERkiTFmRqzrcSjQe+me6L10T/Re2kdNQ4qiKH0cFQSKoih9nL4mCP4W6wocQvReuid6L90TvZd26FM+AkVRFKUtfU0jUBRFUUJQQaAoitLH6TOCQETOFZENIrJZRO6NdX0OFBHZLiKrRGS5iCxx0vqJyHsissn5zol1PcMhIo+LyH4RWe1JC1t3sTzkvKeVIjItdjVvS4R7uV9EdjnvZrmInO/Ju8+5lw0ick5sat0WERkmInNFZK2IrBGRu530Hvde2rmXnvhekkXkcxFZ4dzLfznpo0RkkVPnF0Qk0UlPcvY3O/kjO3VhY0yv/wA+YAswGkgEVgCTYl2vA7yH7UBeSNpvgHud7XuBX8e6nhHq/iVgGrC6o7oD5wNvAQLMAhbFuv5R3Mv9wPfDlJ3k/NaSgFHOb9AX63tw6jYYmOZsZwAbnfr2uPfSzr30xPciQLqznQAscp73bOAaJ/0R4BvO9jeBR5zta4AXOnPdvqIRzAQ2G2O2GmMageeBi2Ncp0PBxcATzvYTwCWxq0pkjDEfA6UhyZHqfjHwpLEsBLJFZPBhqWgURLiXSFwMPG+MaTDGbAM2Y3+LMccYs8cY84WzXQWsA/Lpge+lnXuJRHd+L8YYU+3sJjgfA5wOvOSkh74X9329BJwhInKg1+0rgiAfKPDsF9L+D6U7YoB3RWSpiNzmpA00xuxxtvcCA2NTtU4Rqe499V3d6ZhMHveY6HrEvTjmhGOwvc8e/V5C7gV64HsREZ+ILAf2A+9hNZZyY4zfKeKtb8u9OPkVQO6BXrOvCILewEnGmGnAecC3RORL3kxjdcMeORa4J9fd4S/AGGAqsAf4XUxrcwCISDrwMnCPMabSm9fT3kuYe+mR78UY02yMmQoMxWoqE7r6mn1FEOwChnn2hzppPQZjzC7nez8wB/sD2eeq5873/tjV8ICJVPce966MMfucP28A+DtBM0O3vhcRScA2nM8YY15xknvkewl3Lz31vbgYY8qBucDxWFNcvJPlrW/LvTj5WUDJgV6rrwiCxcA4x/OeiHWqvBbjOkWNiKSJSIa7DZwNrMbew9ecYl8DXo1NDTtFpLq/BnzVGaUyC6jwmCq6JSG28kux7wbsvVzjjOwYBYwDPj/c9QuHY0d+DFhnjHnQk9Xj3kuke+mh76W/iGQ72ynAWVifx1zgCqdY6Htx39cVwIeOJndgxNpLfrg+2FEPG7H2th/Huj4HWPfR2FEOK4A1bv2xtsAPgE3A+0C/WNc1Qv2fw6rmTVj75s2R6o4dNfGw855WATNiXf8o7uUpp64rnT/mYE/5Hzv3sgE4L9b199TrJKzZZyWw3Pmc3xPfSzv30hPfy9HAMqfOq4GfOumjscJqM/AikOSkJzv7m5380Z25roaYUBRF6eP0FdOQoiiKEgEVBIqiKH0cFQSKoih9HBUEiqIofRwVBIqiKH0cFQSKchgRkVNF5I1Y10NRvKggUBRF6eOoIFCUMIjI9U5c+OUi8lcnEFi1iPzeiRP/gYj0d8pOFZGFTnCzOZ4Y/mNF5H0ntvwXIjLGOX26iLwkIutF5JnORItUlEOJCgJFCUFEJgJXAycaG/yrGbgOSAOWGGOOBOYBP3MOeRL4oTHmaOxMVjf9GeBhY8wU4ATsjGSw0THvwcbFHw2c2MW3pCjtEt9xEUXpc5wBTAcWO531FGzwtQDwglPmaeAVEckCso0x85z0J4AXndhQ+caYOQDGmHoA53yfG2MKnf3lwEjg0y6/K0WJgAoCRWmLAE8YY+5rlSjynyHlOhufpcGz3Yz+D5UYo6YhRWnLB8AVIjIAWtbxHYH9v7gRIL8CfGqMqQDKRORkJ/0GYJ6xK2UVisglzjmSRCT1cN6EokSL9kQUJQRjzFoR+Ql2Rbg4bKTRbwE1wEwnbz/WjwA2DPAjTkO/FbjJSb8B+KuIPOCc48rDeBuKEjUafVRRokREqo0x6bGuh6IcatQ0pCiK0sdRjUBRFKWPoxqBoihKH0cFgaIoSh9HBYGiKEofRwWBoihKH0cFgaIoSh/n/wHywHG4F5/Z0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Vgg-Lite model (first approach) accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Vgg-Lite model (first approach) loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-exchange",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-rover",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.(h)\n",
    "# AlexNet\n",
    "model_alex = Sequential([\n",
    "    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=input_shape),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alex.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_alex, to_file='vgg_lite_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alexnet\n",
    "optimizer = SGD(learning_rate = 0.001, momentum = 0.9)\n",
    "#optimizer = RMSprop(learning_rate = 0.0001)\n",
    "model_alex.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 5, verbose = 2,\n",
    "                              mode = 'auto', min_delta = 0.0001, cooldown = 0, min_lr = 0)\n",
    "snapshot_name = 'alex_image_model'\n",
    "checkpoint = ModelCheckpoint(filepath = snapshot_name + \".{epoch:02d}-{val_accuracy:.2f}.h5\",\n",
    "                             monitor = 'val_accuracy', verbose = 0, save_best_only = True,\n",
    "                             save_weights_only = True, mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_alex.fit(train_generator, steps_per_epoch = training_samples // batch_size,\n",
    "                                  epochs = epochs, validation_data = validation_generator, \n",
    "                                  validation_steps = validation_samples // batch_size,\n",
    "                                  callbacks = [reduce_lr, checkpoint])\n",
    "\n",
    "model_alex.save_weights('model_alex_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alex.evaluate_generator(test_generator, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('AlexNet-Lite model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('AlexNet-Lite model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-harvard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-coast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-industry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "model_json = model.to_json()  # Input right name of the model\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model and weights\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "json_file = open(\"model.json\", \"r\") # Input right name of the model\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_vgg_model = model_from_json(loaded_model_json)\n",
    "loaded_vgg_model.load_weights (\"Weight.h5\")  # Input right name of the weight\n",
    "print(\"Model load complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
